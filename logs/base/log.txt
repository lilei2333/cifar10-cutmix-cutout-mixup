Namespace(GPU_ids='0', alpha=1.0, batch_size=128, cutmix_prob=0.0, cutout=False, device='cuda', epochs=200, length=16, lr=0.1, mixup=False, momentum=0.9, n_holes=1, output_dir='./logs/base', print_freq=50, resume=None, save_every=10, seed=111, start_epoch=0, validation=True, weight_decay=0.0001, workers=4)
resnet32: #params=464.2K
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (linear): Linear(in_features=64, out_features=10, bias=True)
  )
)
CrossEntropyLoss()
Building dataset...
Start training
Epoch: [0]
epoch 0/200, train:, losses=1.4307, top1=33.0244, 0=35.1111, 1=46.3556, 2=15.5778, 3=20.9778, 4=25.2889, 5=29.0000, 6=41.9111, 7=35.9556, 8=42.7556, 9=37.3111, val:, losses=1.5681, top1=43.8000, 0=57.4000, 1=58.6000, 2=8.0000, 3=8.8000, 4=57.4000, 5=35.2000, 6=78.0000, 7=44.6000, 8=36.2000, 9=53.8000, test:, losses=1.5505, top1=44.1200, 0=60.6000, 1=56.3000, 2=7.6000, 3=6.8000, 4=58.7000, 5=38.4000, 6=76.8000, 7=46.7000, 8=36.3000, 9=53.0000, 25.3s 25.3s/1.4h
Epoch: [1]
epoch 1/200, train:, losses=1.0181, top1=52.1533, 0=55.8667, 1=69.6667, 2=36.4667, 3=26.7111, 4=35.6444, 5=45.2222, 6=65.0889, 7=59.7333, 8=64.4444, 9=62.6889, val:, losses=1.1523, top1=58.1400, 0=76.6000, 1=77.8000, 2=45.0000, 3=14.8000, 4=32.2000, 5=64.0000, 6=79.6000, 7=75.6000, 8=42.6000, 9=73.2000, test:, losses=1.1672, top1=57.8800, 0=76.0000, 1=77.3000, 2=47.4000, 3=18.5000, 4=29.5000, 5=61.9000, 6=79.9000, 7=73.5000, 8=42.7000, 9=72.1000, 38.4s 1.1m/1.8h
Epoch: [2]
epoch 2/200, train:, losses=0.8221, top1=62.1200, 0=64.8444, 1=79.9111, 2=48.0000, 3=38.1111, 4=52.2444, 5=49.8000, 6=71.4889, 7=65.6889, 8=75.6889, 9=75.4222, val:, losses=0.9794, top1=66.3000, 0=75.4000, 1=88.8000, 2=39.2000, 3=44.0000, 4=60.0000, 5=55.2000, 6=77.0000, 7=63.6000, 8=77.0000, 9=82.8000, test:, losses=0.9732, top1=66.2700, 0=74.1000, 1=90.4000, 2=39.0000, 3=48.8000, 4=58.2000, 5=57.1000, 6=78.0000, 7=60.4000, 8=77.2000, 9=79.5000, 48.2s 1.9m/2.1h
Epoch: [3]
epoch 3/200, train:, losses=0.6987, top1=68.1600, 0=70.5333, 1=84.9111, 2=55.3111, 3=45.7111, 4=60.2667, 5=57.4000, 6=74.4222, 7=70.5333, 8=81.0444, 9=81.4667, val:, losses=0.9496, top1=66.3000, 0=66.0000, 1=90.0000, 2=77.8000, 3=66.8000, 4=65.4000, 5=33.2000, 6=48.0000, 7=55.6000, 8=83.8000, 9=76.4000, test:, losses=0.9619, top1=65.8000, 0=63.9000, 1=89.0000, 2=77.0000, 3=65.2000, 4=63.5000, 5=36.1000, 6=48.0000, 7=60.0000, 8=84.3000, 9=71.0000, 48.3s 2.7m/2.2h
Epoch: [4]
epoch 4/200, train:, losses=0.6121, top1=72.4689, 0=74.9556, 1=87.0667, 2=61.9333, 3=53.1111, 4=67.5556, 5=60.4889, 6=76.8667, 7=75.5333, 8=84.5111, 9=82.6667, val:, losses=0.8494, top1=70.3400, 0=67.6000, 1=75.6000, 2=70.2000, 3=65.2000, 4=58.0000, 5=66.6000, 6=51.0000, 7=70.6000, 8=89.8000, 9=88.8000, test:, losses=0.8437, top1=70.4200, 0=70.0000, 1=76.9000, 2=71.0000, 3=65.1000, 4=55.5000, 5=68.2000, 6=51.7000, 7=70.7000, 8=89.2000, 9=85.9000, 49.8s 3.5m/2.3h
Epoch: [5]
epoch 5/200, train:, losses=0.5457, top1=75.5556, 0=78.1778, 1=88.3111, 2=65.1111, 3=57.5778, 4=72.5111, 5=64.4667, 6=80.1778, 7=78.4000, 8=86.1111, 9=84.7111, val:, losses=0.9155, top1=70.7000, 0=77.4000, 1=95.6000, 2=28.8000, 3=76.8000, 4=53.0000, 5=69.6000, 6=72.6000, 7=78.0000, 8=73.0000, 9=82.2000, test:, losses=0.9359, top1=70.2800, 0=81.1000, 1=96.1000, 2=25.7000, 3=77.5000, 4=53.9000, 5=71.0000, 6=69.1000, 7=76.4000, 8=72.2000, 9=79.8000, 51.1s 4.4m/2.4h
Epoch: [6]
epoch 6/200, train:, losses=0.4991, top1=77.8556, 0=80.0000, 1=89.4000, 2=68.5778, 3=61.5556, 4=75.5556, 5=66.2000, 6=81.8667, 7=81.1111, 8=87.5333, 9=86.7556, val:, losses=0.7177, top1=75.9400, 0=85.6000, 1=83.8000, 2=69.2000, 3=69.4000, 4=74.4000, 5=54.2000, 6=64.2000, 7=90.0000, 8=75.2000, 9=93.4000, test:, losses=0.7218, top1=75.4200, 0=85.7000, 1=87.0000, 2=66.6000, 3=67.6000, 4=75.6000, 5=54.5000, 6=60.7000, 7=88.4000, 8=75.2000, 9=92.9000, 49.9s 5.2m/2.5h
Epoch: [7]
epoch 7/200, train:, losses=0.4621, top1=79.5933, 0=81.1556, 1=90.4222, 2=72.0444, 3=63.6222, 4=78.3333, 5=68.9778, 6=82.7333, 7=82.9333, 8=88.6444, 9=87.0667, val:, losses=0.7452, top1=75.6000, 0=79.8000, 1=74.4000, 2=51.4000, 3=40.6000, 4=84.2000, 5=73.2000, 6=77.0000, 7=89.2000, 8=92.4000, 9=93.8000, test:, losses=0.7462, top1=75.4900, 0=82.9000, 1=78.5000, 2=51.1000, 3=38.1000, 4=82.5000, 5=74.9000, 6=75.4000, 7=86.9000, 8=92.5000, 9=92.1000, 47.0s 6.0m/2.5h
Epoch: [8]
epoch 8/200, train:, losses=0.4296, top1=80.9778, 0=82.9556, 1=91.3556, 2=73.1778, 3=65.5778, 4=80.2667, 5=69.2667, 6=84.8444, 7=84.6889, 8=88.8667, 9=88.7778, val:, losses=0.6332, top1=78.2400, 0=79.0000, 1=92.2000, 2=60.2000, 3=52.6000, 4=79.4000, 5=69.8000, 6=91.4000, 7=85.8000, 8=89.0000, 9=83.0000, test:, losses=0.6538, top1=77.8800, 0=77.8000, 1=92.9000, 2=57.2000, 3=52.0000, 4=80.8000, 5=71.4000, 6=93.8000, 7=82.9000, 8=88.4000, 9=81.6000, 48.8s 6.8m/2.5h
Epoch: [9]
epoch 9/200, train:, losses=0.4084, top1=81.8733, 0=84.1111, 1=91.0444, 2=75.4000, 3=67.6667, 4=80.5111, 5=71.6222, 6=85.2222, 7=84.4222, 8=89.7778, 9=88.9556, val:, losses=0.6021, top1=79.6800, 0=76.6000, 1=97.6000, 2=65.6000, 3=68.8000, 4=89.0000, 5=54.2000, 6=88.4000, 7=83.6000, 8=88.4000, 9=84.6000, test:, losses=0.6180, top1=79.9100, 0=75.9000, 1=98.2000, 2=67.9000, 3=68.7000, 4=88.2000, 5=57.3000, 6=88.4000, 7=81.9000, 8=89.1000, 9=83.5000, 49.3s 7.6m/2.5h
Epoch: [10]
epoch 10/200, train:, losses=0.3877, top1=83.0467, 0=85.0222, 1=92.3333, 2=75.8667, 3=68.7556, 4=82.7333, 5=72.9333, 6=85.7556, 7=86.2444, 8=90.5111, 9=90.3111, val:, losses=0.5928, top1=79.6400, 0=74.4000, 1=87.4000, 2=74.8000, 3=48.2000, 4=67.2000, 5=87.0000, 6=88.0000, 7=86.6000, 8=91.2000, 9=91.6000, test:, losses=0.6118, top1=78.9800, 0=74.3000, 1=88.3000, 2=71.0000, 3=47.6000, 4=67.0000, 5=88.7000, 6=86.1000, 7=84.9000, 8=90.9000, 9=91.0000, 50.7s 8.4m/2.6h
Epoch: [11]
epoch 11/200, train:, losses=0.3656, top1=83.7556, 0=85.9778, 1=92.5556, 2=78.1778, 3=69.8000, 4=82.8889, 5=73.4667, 6=87.3111, 7=86.6000, 8=90.6889, 9=90.0889, val:, losses=0.5833, top1=80.1800, 0=87.8000, 1=85.2000, 2=76.0000, 3=44.0000, 4=81.8000, 5=74.6000, 6=79.8000, 7=86.6000, 8=90.4000, 9=95.6000, test:, losses=0.5993, top1=79.8500, 0=87.6000, 1=90.0000, 2=74.7000, 3=40.8000, 4=80.0000, 5=76.8000, 6=78.1000, 7=86.5000, 8=88.6000, 9=95.4000, 49.1s 9.3m/2.6h
Epoch: [12]
epoch 12/200, train:, losses=0.3616, top1=83.7778, 0=85.9778, 1=91.7111, 2=78.0444, 3=70.3778, 4=83.3333, 5=73.9778, 6=87.2444, 7=86.8444, 8=90.4222, 9=89.8444, val:, losses=0.5754, top1=80.9200, 0=85.0000, 1=93.0000, 2=81.2000, 3=59.2000, 4=68.2000, 5=78.6000, 6=88.2000, 7=77.4000, 8=84.8000, 9=93.6000, test:, losses=0.5773, top1=80.9300, 0=84.2000, 1=95.5000, 2=81.6000, 3=56.1000, 4=68.5000, 5=79.5000, 6=88.1000, 7=76.6000, 8=84.8000, 9=94.4000, 50.9s 10.1m/2.6h
Epoch: [13]
epoch 13/200, train:, losses=0.3372, top1=85.0311, 0=87.1111, 1=93.0889, 2=79.8889, 3=71.8222, 4=84.9556, 5=74.8222, 6=88.1333, 7=87.9333, 8=91.7111, 9=90.8444, val:, losses=0.5901, top1=80.6200, 0=80.8000, 1=95.6000, 2=68.8000, 3=82.8000, 4=89.0000, 5=57.2000, 6=91.4000, 7=73.6000, 8=82.0000, 9=85.0000, test:, losses=0.5930, top1=80.3900, 0=81.1000, 1=97.2000, 2=69.7000, 3=82.1000, 4=87.2000, 5=60.4000, 6=90.6000, 7=72.9000, 8=81.9000, 9=80.8000, 52.9s 11.0m/2.6h
Epoch: [14]
epoch 14/200, train:, losses=0.3344, top1=85.3578, 0=87.6667, 1=93.4444, 2=79.3778, 3=73.0889, 4=84.6222, 5=75.2222, 6=88.6444, 7=88.5778, 8=91.6444, 9=91.2889, val:, losses=0.5028, top1=83.4800, 0=90.8000, 1=90.8000, 2=70.4000, 3=70.0000, 4=86.0000, 5=64.2000, 6=94.8000, 7=83.2000, 8=91.4000, 9=93.2000, test:, losses=0.4986, top1=83.8600, 0=91.0000, 1=93.0000, 2=68.5000, 3=71.8000, 4=86.8000, 5=67.6000, 6=94.6000, 7=81.6000, 8=90.7000, 9=93.0000, 50.2s 11.8m/2.6h
Epoch: [15]
epoch 15/200, train:, losses=0.3181, top1=85.9222, 0=87.8000, 1=93.2222, 2=81.2000, 3=73.3111, 4=85.6889, 5=76.6889, 6=88.6667, 7=88.9111, 8=92.2667, 9=91.4667, val:, losses=0.5831, top1=80.5400, 0=80.0000, 1=97.8000, 2=67.0000, 3=74.0000, 4=87.4000, 5=61.4000, 6=92.0000, 7=78.2000, 8=90.0000, 9=77.6000, test:, losses=0.5945, top1=80.8400, 0=83.3000, 1=98.5000, 2=67.7000, 3=73.8000, 4=86.4000, 5=64.8000, 6=93.9000, 7=76.6000, 8=89.0000, 9=74.4000, 52.0s 12.7m/2.7h
Epoch: [16]
epoch 16/200, train:, losses=0.3082, top1=86.3333, 0=88.1111, 1=93.6667, 2=81.0000, 3=74.1778, 4=86.4667, 5=76.7333, 6=89.6667, 7=89.6000, 8=92.5778, 9=91.3333, val:, losses=0.6035, top1=80.1000, 0=72.4000, 1=85.4000, 2=83.2000, 3=47.6000, 4=71.4000, 5=73.6000, 6=95.0000, 7=94.4000, 8=83.6000, 9=94.4000, test:, losses=0.6003, top1=80.8700, 0=73.9000, 1=86.5000, 2=84.7000, 3=46.8000, 4=75.7000, 5=71.9000, 6=95.3000, 7=94.0000, 8=85.3000, 9=94.6000, 52.6s 13.6m/2.7h
Epoch: [17]
epoch 17/200, train:, losses=0.3044, top1=86.4333, 0=88.3111, 1=93.9556, 2=81.5556, 3=75.1111, 4=86.0667, 5=76.9333, 6=89.2667, 7=89.1556, 8=91.9778, 9=92.0000, val:, losses=0.5182, top1=83.6200, 0=91.6000, 1=88.8000, 2=76.4000, 3=73.4000, 4=89.6000, 5=78.0000, 6=86.6000, 7=83.4000, 8=90.2000, 9=78.2000, test:, losses=0.5270, top1=82.7200, 0=90.8000, 1=88.2000, 2=74.5000, 3=74.1000, 4=89.4000, 5=78.6000, 6=83.8000, 7=82.4000, 8=91.0000, 9=74.4000, 50.9s 14.4m/2.7h
Epoch: [18]
epoch 18/200, train:, losses=0.2970, top1=87.0022, 0=88.8444, 1=93.9333, 2=82.9333, 3=75.6444, 4=86.4667, 5=78.4222, 6=89.9778, 7=89.8000, 8=92.1333, 9=91.8667, val:, losses=0.5965, top1=81.2800, 0=71.0000, 1=83.6000, 2=63.4000, 3=62.8000, 4=89.8000, 5=64.8000, 6=94.4000, 7=95.0000, 8=93.6000, 9=94.4000, test:, losses=0.5899, top1=81.8800, 0=76.9000, 1=86.2000, 2=62.7000, 3=61.1000, 4=89.7000, 5=67.5000, 6=93.3000, 7=95.6000, 8=91.8000, 9=94.0000, 51.9s 15.3m/2.7h
Epoch: [19]
epoch 19/200, train:, losses=0.2836, top1=87.4667, 0=88.9778, 1=94.2000, 2=83.3111, 3=76.0667, 4=87.5111, 5=78.9111, 6=90.2889, 7=90.2667, 8=92.7556, 9=92.3778, val:, losses=0.5382, top1=82.3000, 0=76.4000, 1=96.6000, 2=86.8000, 3=44.4000, 4=81.0000, 5=79.0000, 6=84.4000, 7=91.8000, 8=92.8000, 9=89.8000, test:, losses=0.5419, top1=82.6200, 0=80.1000, 1=97.7000, 2=86.7000, 3=45.2000, 4=80.7000, 5=78.9000, 6=84.1000, 7=91.8000, 8=91.2000, 9=89.8000, 50.8s 16.1m/2.7h
Epoch: [20]
epoch 20/200, train:, losses=0.2827, top1=87.4911, 0=88.2889, 1=93.7556, 2=83.2667, 3=76.6222, 4=87.9111, 5=79.1333, 6=90.4000, 7=90.1333, 8=92.8000, 9=92.6000, val:, losses=0.4869, top1=83.3800, 0=91.4000, 1=97.2000, 2=68.6000, 3=65.0000, 4=80.8000, 5=75.4000, 6=89.8000, 7=93.0000, 8=88.4000, 9=84.2000, test:, losses=0.5012, top1=83.5500, 0=92.0000, 1=95.7000, 2=67.8000, 3=66.5000, 4=80.3000, 5=79.9000, 6=90.6000, 7=92.1000, 8=87.8000, 9=82.8000, 50.9s 17.0m/2.7h
Epoch: [21]
epoch 21/200, train:, losses=0.2712, top1=87.8444, 0=88.9556, 1=94.6667, 2=84.2667, 3=76.8000, 4=87.4889, 5=79.3111, 6=90.4222, 7=90.5333, 8=93.0222, 9=92.9778, val:, losses=0.4672, top1=83.9600, 0=80.6000, 1=94.0000, 2=77.2000, 3=65.2000, 4=80.2000, 5=71.4000, 6=93.4000, 7=92.8000, 8=94.4000, 9=90.4000, test:, losses=0.4755, top1=84.3000, 0=80.5000, 1=96.0000, 2=76.1000, 3=66.6000, 4=81.0000, 5=74.8000, 6=93.8000, 7=91.7000, 8=92.9000, 9=89.6000, 50.6s 17.8m/2.7h
Epoch: [22]
epoch 22/200, train:, losses=0.2690, top1=88.0400, 0=89.4444, 1=94.6444, 2=83.3333, 3=77.3778, 4=87.5778, 5=80.0667, 6=91.2222, 7=90.9111, 8=92.9556, 9=92.8667, val:, losses=0.4589, top1=84.9200, 0=90.0000, 1=94.2000, 2=83.4000, 3=66.2000, 4=93.4000, 5=72.6000, 6=85.6000, 7=84.2000, 8=94.2000, 9=85.4000, test:, losses=0.4617, top1=85.1800, 0=90.7000, 1=94.7000, 2=83.1000, 3=66.0000, 4=93.8000, 5=74.4000, 6=86.5000, 7=84.1000, 8=93.8000, 9=84.7000, 50.0s 18.7m/2.7h
Epoch: [23]
epoch 23/200, train:, losses=0.2624, top1=88.5067, 0=89.5111, 1=94.4889, 2=84.2000, 3=78.5333, 4=89.0889, 5=80.5778, 6=91.0667, 7=91.4667, 8=92.9778, 9=93.1556, val:, losses=0.4914, top1=84.0600, 0=84.8000, 1=90.6000, 2=70.6000, 3=87.0000, 4=84.4000, 5=61.6000, 6=82.8000, 7=89.6000, 8=95.4000, 9=93.8000, test:, losses=0.5004, top1=83.4400, 0=84.4000, 1=91.8000, 2=69.1000, 3=86.3000, 4=85.5000, 5=63.8000, 6=78.4000, 7=88.9000, 8=93.9000, 9=92.3000, 47.4s 19.5m/2.7h
Epoch: [24]
epoch 24/200, train:, losses=0.2594, top1=88.4911, 0=89.5333, 1=94.5778, 2=85.0444, 3=78.1778, 4=88.4889, 5=80.0667, 6=91.2000, 7=91.3111, 8=93.6000, 9=92.9111, val:, losses=0.4669, top1=84.9000, 0=87.2000, 1=92.8000, 2=69.0000, 3=74.6000, 4=85.0000, 5=73.2000, 6=89.2000, 7=91.8000, 8=91.4000, 9=94.8000, test:, losses=0.4545, top1=85.5000, 0=88.8000, 1=94.4000, 2=70.9000, 3=75.7000, 4=84.1000, 5=75.3000, 6=89.3000, 7=92.1000, 8=89.9000, 9=94.5000, 47.1s 20.2m/2.7h
Epoch: [25]
epoch 25/200, train:, losses=0.2492, top1=88.8200, 0=90.0889, 1=94.7778, 2=85.1333, 3=78.3778, 4=88.7111, 5=81.3111, 6=91.4889, 7=91.1778, 8=93.6667, 9=93.4667, val:, losses=0.4491, top1=85.1200, 0=94.6000, 1=88.2000, 2=84.4000, 3=66.6000, 4=86.4000, 5=73.4000, 6=86.2000, 7=91.8000, 8=89.0000, 9=90.6000, test:, losses=0.4731, top1=85.6300, 0=94.8000, 1=89.4000, 2=85.7000, 3=67.3000, 4=86.9000, 5=76.9000, 6=85.6000, 7=90.1000, 8=88.1000, 9=91.5000, 48.6s 21.1m/2.7h
Epoch: [26]
epoch 26/200, train:, losses=0.2435, top1=89.1733, 0=90.4889, 1=94.9556, 2=84.9333, 3=79.6889, 4=89.3556, 5=82.1556, 6=91.3556, 7=91.6889, 8=93.8444, 9=93.2667, val:, losses=0.5488, top1=83.1000, 0=78.6000, 1=93.6000, 2=74.0000, 3=76.0000, 4=91.6000, 5=61.2000, 6=95.2000, 7=73.8000, 8=94.8000, 9=92.2000, test:, losses=0.5465, top1=83.1100, 0=80.8000, 1=94.4000, 2=74.3000, 3=74.0000, 4=90.4000, 5=63.5000, 6=95.1000, 7=72.6000, 8=94.7000, 9=91.3000, 49.9s 21.9m/2.7h
Epoch: [27]
epoch 27/200, train:, losses=0.2411, top1=89.3067, 0=90.7111, 1=94.9333, 2=85.9111, 3=79.6889, 4=89.2222, 5=81.5778, 6=91.9333, 7=91.9333, 8=93.8667, 9=93.2889, val:, losses=0.4970, top1=84.0600, 0=82.2000, 1=96.4000, 2=74.4000, 3=55.8000, 4=77.2000, 5=88.8000, 6=91.4000, 7=90.2000, 8=90.6000, 9=93.6000, test:, losses=0.5075, top1=83.8200, 0=81.9000, 1=96.7000, 2=73.5000, 3=56.3000, 4=78.1000, 5=88.0000, 6=90.3000, 7=90.7000, 8=90.9000, 9=91.8000, 51.6s 22.7m/2.7h
Epoch: [28]
epoch 28/200, train:, losses=0.2365, top1=89.4978, 0=90.7333, 1=95.3333, 2=86.0444, 3=79.9333, 4=89.5111, 5=82.4222, 6=91.1778, 7=91.8444, 8=94.1333, 9=93.8444, val:, losses=0.5403, top1=83.6600, 0=84.6000, 1=94.2000, 2=88.0000, 3=38.2000, 4=85.2000, 5=78.0000, 6=87.0000, 7=93.0000, 8=96.2000, 9=92.2000, test:, losses=0.5634, top1=82.8500, 0=86.0000, 1=95.7000, 2=87.0000, 3=36.0000, 4=84.9000, 5=74.8000, 6=87.7000, 7=92.3000, 8=92.4000, 9=91.7000, 51.2s 23.6m/2.7h
Epoch: [29]
epoch 29/200, train:, losses=0.2389, top1=89.3778, 0=90.4889, 1=94.9556, 2=86.4222, 3=79.9333, 4=88.9778, 5=81.5556, 6=91.9778, 7=92.1333, 8=93.7333, 9=93.6000, val:, losses=0.4862, top1=85.1800, 0=92.0000, 1=79.0000, 2=75.8000, 3=80.2000, 4=92.2000, 5=64.6000, 6=93.8000, 7=85.8000, 8=92.2000, 9=96.2000, test:, losses=0.4861, top1=84.5400, 0=90.7000, 1=82.1000, 2=73.8000, 3=79.9000, 4=90.6000, 5=65.5000, 6=93.1000, 7=83.9000, 8=90.1000, 9=95.7000, 50.3s 24.4m/2.7h
Epoch: [30]
epoch 30/200, train:, losses=0.2290, top1=89.7667, 0=91.0222, 1=94.7556, 2=86.7556, 3=80.6667, 4=90.2000, 5=82.8222, 6=92.3556, 7=91.6889, 8=93.7111, 9=93.6889, val:, losses=0.3997, top1=86.4400, 0=87.4000, 1=93.6000, 2=82.8000, 3=71.4000, 4=91.0000, 5=80.4000, 6=86.6000, 7=89.8000, 8=94.0000, 9=87.4000, test:, losses=0.4245, top1=86.5000, 0=88.1000, 1=94.5000, 2=80.4000, 3=72.8000, 4=92.0000, 5=82.0000, 6=87.7000, 7=90.2000, 8=91.3000, 9=86.0000, 49.4s 25.3m/2.7h
Epoch: [31]
epoch 31/200, train:, losses=0.2244, top1=90.0644, 0=91.2444, 1=95.7111, 2=86.9111, 3=80.8000, 4=90.1333, 5=83.0667, 6=92.4667, 7=92.3333, 8=94.3111, 9=93.6667, val:, losses=0.4945, top1=83.9600, 0=82.2000, 1=97.2000, 2=90.6000, 3=70.2000, 4=86.0000, 5=68.6000, 6=90.6000, 7=82.0000, 8=92.6000, 9=79.6000, test:, losses=0.5197, top1=83.8000, 0=85.0000, 1=97.1000, 2=90.2000, 3=67.8000, 4=85.3000, 5=70.4000, 6=91.7000, 7=79.4000, 8=92.1000, 9=79.0000, 50.5s 26.1m/2.7h
Epoch: [32]
epoch 32/200, train:, losses=0.2228, top1=89.9778, 0=91.2000, 1=95.5556, 2=86.3778, 3=80.7778, 4=89.9333, 5=82.7333, 6=92.7333, 7=91.6222, 8=94.5111, 9=94.3333, val:, losses=0.5287, top1=83.7600, 0=91.0000, 1=96.4000, 2=92.2000, 3=54.8000, 4=88.2000, 5=59.4000, 6=90.2000, 7=91.8000, 8=88.4000, 9=85.2000, test:, losses=0.5513, top1=83.4900, 0=91.5000, 1=95.5000, 2=91.0000, 3=52.9000, 4=89.2000, 5=60.3000, 6=91.1000, 7=92.6000, 8=86.5000, 9=84.3000, 50.3s 26.9m/2.7h
Epoch: [33]
epoch 33/200, train:, losses=0.2221, top1=90.0400, 0=90.9778, 1=95.6222, 2=86.9556, 3=81.0222, 4=90.6444, 5=82.8222, 6=92.4444, 7=92.2444, 8=94.0000, 9=93.6667, val:, losses=0.4720, top1=85.5200, 0=90.0000, 1=94.6000, 2=70.0000, 3=53.0000, 4=90.2000, 5=85.8000, 6=93.0000, 7=94.2000, 8=94.0000, 9=90.4000, test:, losses=0.4997, top1=84.9500, 0=89.2000, 1=95.4000, 2=69.4000, 3=50.9000, 4=87.4000, 5=86.8000, 6=94.4000, 7=93.6000, 8=92.8000, 9=89.6000, 49.8s 27.8m/2.7h
Epoch: [34]
epoch 34/200, train:, losses=0.2155, top1=90.3467, 0=91.7778, 1=95.6889, 2=87.0000, 3=81.7111, 4=90.5333, 5=83.0444, 6=93.0222, 7=92.3778, 8=94.1556, 9=94.1556, val:, losses=0.4859, top1=84.1600, 0=92.0000, 1=97.0000, 2=75.6000, 3=83.8000, 4=84.0000, 5=62.4000, 6=84.8000, 7=87.8000, 8=92.8000, 9=81.4000, test:, losses=0.4927, top1=84.2500, 0=92.2000, 1=98.0000, 2=73.0000, 3=85.9000, 4=85.9000, 5=64.4000, 6=82.8000, 7=88.0000, 8=90.8000, 9=81.5000, 50.8s 28.6m/2.7h
Epoch: [35]
epoch 35/200, train:, losses=0.2140, top1=90.4178, 0=91.4444, 1=95.9111, 2=87.1556, 3=81.5333, 4=90.4222, 5=83.4444, 6=92.8000, 7=92.8000, 8=94.3778, 9=94.2889, val:, losses=0.6153, top1=81.4200, 0=77.4000, 1=92.6000, 2=80.2000, 3=52.2000, 4=62.8000, 5=89.4000, 6=83.4000, 7=96.8000, 8=84.2000, 9=95.2000, test:, losses=0.6092, top1=81.6200, 0=83.0000, 1=94.1000, 2=79.4000, 3=49.2000, 4=61.8000, 5=89.9000, 6=82.1000, 7=97.6000, 8=84.7000, 9=94.4000, 50.9s 29.5m/2.7h
Epoch: [36]
epoch 36/200, train:, losses=0.2093, top1=90.7000, 0=91.1778, 1=95.4000, 2=87.4667, 3=82.4222, 4=90.8444, 5=84.1556, 6=93.0444, 7=93.0222, 8=95.0444, 9=94.4222, val:, losses=0.4301, top1=86.0800, 0=87.8000, 1=97.8000, 2=75.2000, 3=83.2000, 4=86.6000, 5=67.0000, 6=94.8000, 7=89.2000, 8=91.2000, 9=88.0000, test:, losses=0.4271, top1=86.6000, 0=88.5000, 1=97.3000, 2=74.6000, 3=84.3000, 4=85.3000, 5=70.9000, 6=96.3000, 7=89.7000, 8=91.2000, 9=87.9000, 51.9s 30.3m/2.7h
Epoch: [37]
epoch 37/200, train:, losses=0.2115, top1=90.6156, 0=91.6667, 1=95.4667, 2=87.1333, 3=82.0444, 4=91.2667, 5=83.9111, 6=92.8000, 7=92.9111, 8=94.7556, 9=94.2000, val:, losses=0.4377, top1=86.2800, 0=90.0000, 1=88.8000, 2=80.2000, 3=73.2000, 4=91.0000, 5=75.4000, 6=93.4000, 7=86.8000, 8=97.6000, 9=86.4000, test:, losses=0.4442, top1=86.2200, 0=90.6000, 1=90.2000, 2=77.3000, 3=75.1000, 4=90.4000, 5=76.5000, 6=93.0000, 7=87.5000, 8=96.1000, 9=85.5000, 52.1s 31.2m/2.8h
Epoch: [38]
epoch 38/200, train:, losses=0.2058, top1=90.8000, 0=91.8222, 1=95.7111, 2=87.5333, 3=82.6444, 4=90.9556, 5=84.0667, 6=92.9333, 7=93.0667, 8=95.1333, 9=94.1333, val:, losses=0.4699, top1=84.7000, 0=80.8000, 1=90.2000, 2=79.4000, 3=67.0000, 4=81.8000, 5=83.8000, 6=92.4000, 7=89.4000, 8=93.0000, 9=89.2000, test:, losses=0.4509, top1=85.6500, 0=83.1000, 1=93.0000, 2=81.0000, 3=69.3000, 4=81.0000, 5=85.7000, 6=93.8000, 7=88.9000, 8=92.2000, 9=88.5000, 51.1s 32.1m/2.8h
Epoch: [39]
epoch 39/200, train:, losses=0.2076, top1=90.5911, 0=91.5778, 1=95.4222, 2=87.2444, 3=82.5111, 4=90.8444, 5=83.9556, 6=92.9778, 7=92.5778, 8=94.6667, 9=94.1333, val:, losses=0.5046, top1=83.8400, 0=90.6000, 1=88.6000, 2=69.8000, 3=59.0000, 4=80.8000, 5=90.4000, 6=92.0000, 7=92.6000, 8=81.0000, 9=93.6000, test:, losses=0.5043, top1=84.4500, 0=92.0000, 1=92.2000, 2=70.8000, 3=57.1000, 4=80.7000, 5=89.7000, 6=92.1000, 7=93.3000, 8=83.4000, 9=93.2000, 51.4s 32.9m/2.8h
Epoch: [40]
epoch 40/200, train:, losses=0.1998, top1=91.1111, 0=91.9111, 1=95.8222, 2=87.9778, 3=83.3556, 4=91.5778, 5=84.3333, 6=93.2222, 7=93.2000, 8=95.2222, 9=94.4889, val:, losses=0.4402, top1=85.8200, 0=90.8000, 1=93.4000, 2=81.4000, 3=80.2000, 4=71.4000, 5=71.8000, 6=93.0000, 7=94.2000, 8=89.4000, 9=92.6000, test:, losses=0.4251, top1=86.4800, 0=90.7000, 1=94.2000, 2=81.9000, 3=82.6000, 4=74.1000, 5=72.3000, 6=94.3000, 7=94.4000, 8=89.0000, 9=91.3000, 49.5s 33.7m/2.8h
Epoch: [41]
epoch 41/200, train:, losses=0.1976, top1=91.1622, 0=92.0000, 1=95.3778, 2=87.9333, 3=82.9333, 4=91.6889, 5=85.4000, 6=93.1778, 7=93.2000, 8=95.5778, 9=94.3333, val:, losses=0.4450, top1=85.9000, 0=84.0000, 1=97.8000, 2=73.8000, 3=81.8000, 4=92.6000, 5=75.4000, 6=92.2000, 7=84.0000, 8=90.2000, 9=87.2000, test:, losses=0.4559, top1=85.8000, 0=84.5000, 1=98.5000, 2=73.8000, 3=81.0000, 4=91.6000, 5=76.2000, 6=93.1000, 7=82.5000, 8=89.9000, 9=86.9000, 50.7s 34.6m/2.8h
Epoch: [42]
epoch 42/200, train:, losses=0.1994, top1=91.3400, 0=92.4889, 1=95.7556, 2=88.1778, 3=82.9111, 4=91.6444, 5=85.6667, 6=93.7556, 7=93.2222, 8=95.2222, 9=94.5556, val:, losses=0.4674, top1=85.5400, 0=82.2000, 1=89.6000, 2=85.0000, 3=71.4000, 4=87.6000, 5=74.0000, 6=92.6000, 7=90.4000, 8=92.6000, 9=90.0000, test:, losses=0.4437, top1=85.9600, 0=81.0000, 1=93.1000, 2=82.1000, 3=71.7000, 4=87.8000, 5=77.9000, 6=93.0000, 7=88.0000, 8=94.4000, 9=90.6000, 51.7s 35.4m/2.8h
Epoch: [43]
epoch 43/200, train:, losses=0.1895, top1=91.6044, 0=92.3778, 1=96.0667, 2=88.9333, 3=84.4667, 4=91.6889, 5=85.1556, 6=93.9556, 7=93.7778, 8=95.1556, 9=94.4667, val:, losses=0.5055, top1=85.4400, 0=88.0000, 1=72.8000, 2=81.8000, 3=72.0000, 4=87.6000, 5=87.0000, 6=86.8000, 7=89.6000, 8=91.8000, 9=97.0000, test:, losses=0.5103, top1=84.8900, 0=88.1000, 1=72.4000, 2=80.8000, 3=70.9000, 4=88.9000, 5=84.4000, 6=86.3000, 7=89.9000, 8=90.4000, 9=96.8000, 51.0s 36.3m/2.8h
Epoch: [44]
epoch 44/200, train:, losses=0.1943, top1=91.3622, 0=92.2889, 1=95.8222, 2=88.1556, 3=83.1556, 4=92.1778, 5=84.8667, 6=93.8889, 7=93.9111, 8=94.6889, 9=94.6667, val:, losses=0.4788, top1=84.8200, 0=81.4000, 1=85.0000, 2=88.6000, 3=65.8000, 4=94.4000, 5=78.4000, 6=77.0000, 7=88.4000, 8=94.4000, 9=94.8000, test:, losses=0.4825, top1=85.2200, 0=83.0000, 1=88.7000, 2=86.7000, 3=67.5000, 4=94.3000, 5=79.6000, 6=74.6000, 7=90.0000, 8=94.5000, 9=93.3000, 50.7s 37.1m/2.8h
Epoch: [45]
epoch 45/200, train:, losses=0.1922, top1=91.4333, 0=92.4667, 1=95.8000, 2=87.9556, 3=84.0667, 4=91.8444, 5=85.5333, 6=93.3556, 7=93.5333, 8=95.1556, 9=94.6222, val:, losses=0.4410, top1=86.2600, 0=90.2000, 1=93.4000, 2=81.0000, 3=78.4000, 4=87.6000, 5=84.6000, 6=74.8000, 7=88.8000, 8=93.2000, 9=90.6000, test:, losses=0.4445, top1=86.7800, 0=89.9000, 1=94.2000, 2=84.1000, 3=81.9000, 4=86.5000, 5=84.5000, 6=75.6000, 7=89.1000, 8=92.0000, 9=90.0000, 48.9s 38.0m/2.8h
Epoch: [46]
epoch 46/200, train:, losses=0.1884, top1=91.6356, 0=92.5556, 1=95.7333, 2=89.2000, 3=84.1778, 4=91.9556, 5=85.6222, 6=93.6222, 7=93.6000, 8=95.1333, 9=94.7556, val:, losses=0.4075, top1=87.1000, 0=93.4000, 1=93.8000, 2=83.8000, 3=75.0000, 4=87.2000, 5=79.8000, 6=86.0000, 7=90.0000, 8=91.6000, 9=90.4000, test:, losses=0.4415, top1=87.0200, 0=93.4000, 1=94.5000, 2=82.6000, 3=74.2000, 4=89.0000, 5=80.4000, 6=87.2000, 7=89.2000, 8=89.5000, 9=90.2000, 50.3s 38.8m/2.8h
Epoch: [47]
epoch 47/200, train:, losses=0.1906, top1=91.3889, 0=92.3111, 1=96.0667, 2=89.0222, 3=83.4889, 4=91.8667, 5=84.9778, 6=93.2667, 7=93.5556, 8=95.0889, 9=94.2444, val:, losses=0.4547, top1=85.0800, 0=88.2000, 1=87.6000, 2=72.8000, 3=58.0000, 4=85.0000, 5=89.6000, 6=86.4000, 7=93.2000, 8=94.8000, 9=95.2000, test:, losses=0.4582, top1=85.9700, 0=90.0000, 1=89.7000, 2=72.6000, 3=60.5000, 4=86.2000, 5=92.0000, 6=86.4000, 7=92.3000, 8=95.0000, 9=95.0000, 50.2s 39.6m/2.8h
Epoch: [48]
epoch 48/200, train:, losses=0.1885, top1=91.6467, 0=93.0222, 1=95.8000, 2=88.7333, 3=84.1778, 4=91.9111, 5=85.3778, 6=94.0000, 7=94.0000, 8=94.9333, 9=94.5111, val:, losses=0.4851, top1=85.3000, 0=95.4000, 1=89.8000, 2=78.2000, 3=86.2000, 4=90.2000, 5=67.0000, 6=91.0000, 7=74.0000, 8=90.8000, 9=90.4000, test:, losses=0.4859, top1=84.9200, 0=95.8000, 1=89.8000, 2=77.0000, 3=85.5000, 4=88.6000, 5=66.9000, 6=90.4000, 7=73.7000, 8=91.4000, 9=90.1000, 50.1s 40.5m/2.8h
Epoch: [49]
epoch 49/200, train:, losses=0.1861, top1=91.8022, 0=92.7111, 1=95.9556, 2=89.0667, 3=84.7333, 4=92.4889, 5=85.7111, 6=93.6000, 7=93.9333, 8=95.2889, 9=94.5333, val:, losses=0.4595, top1=85.0400, 0=92.0000, 1=98.0000, 2=76.0000, 3=85.6000, 4=83.2000, 5=75.8000, 6=84.0000, 7=82.6000, 8=90.8000, 9=82.4000, test:, losses=0.4804, top1=85.1400, 0=93.6000, 1=97.7000, 2=75.2000, 3=84.5000, 4=81.7000, 5=79.8000, 6=84.0000, 7=84.3000, 8=91.1000, 9=79.5000, 50.5s 41.3m/2.8h
Epoch: [50]
epoch 50/200, train:, losses=0.1865, top1=91.6956, 0=92.2000, 1=96.2667, 2=88.5778, 3=84.8222, 4=91.8222, 5=86.2000, 6=93.4889, 7=93.6667, 8=95.0889, 9=94.8222, val:, losses=0.4756, top1=84.9200, 0=83.2000, 1=95.8000, 2=86.0000, 3=69.8000, 4=84.2000, 5=88.6000, 6=89.0000, 7=80.8000, 8=89.0000, 9=82.8000, test:, losses=0.4932, top1=84.7300, 0=83.9000, 1=96.4000, 2=83.7000, 3=70.4000, 4=83.0000, 5=88.5000, 6=88.6000, 7=81.1000, 8=92.2000, 9=79.5000, 50.2s 42.1m/2.8h
Epoch: [51]
epoch 51/200, train:, losses=0.1823, top1=91.7978, 0=92.9778, 1=96.1111, 2=89.2444, 3=84.2000, 4=91.8889, 5=86.4667, 6=93.9778, 7=93.5111, 8=95.2444, 9=94.3556, val:, losses=0.5138, top1=84.6400, 0=77.2000, 1=86.4000, 2=72.4000, 3=76.4000, 4=81.8000, 5=86.6000, 6=93.0000, 7=87.4000, 8=88.2000, 9=97.0000, test:, losses=0.5032, top1=85.4200, 0=76.4000, 1=87.5000, 2=71.4000, 3=78.3000, 4=83.4000, 5=88.0000, 6=92.9000, 7=89.5000, 8=89.9000, 9=96.9000, 50.4s 43.0m/2.8h
Epoch: [52]
epoch 52/200, train:, losses=0.1813, top1=91.9889, 0=93.0667, 1=96.4222, 2=89.0667, 3=84.8667, 4=92.4667, 5=86.2889, 6=93.8889, 7=93.5111, 8=95.3333, 9=94.9778, val:, losses=0.4750, top1=85.1000, 0=86.8000, 1=95.0000, 2=78.4000, 3=81.4000, 4=89.8000, 5=67.2000, 6=95.4000, 7=92.8000, 8=80.8000, 9=83.4000, test:, losses=0.4903, top1=85.3500, 0=88.4000, 1=95.8000, 2=77.7000, 3=80.1000, 4=88.5000, 5=70.1000, 6=95.1000, 7=92.4000, 8=82.2000, 9=83.2000, 48.6s 43.8m/2.8h
Epoch: [53]
epoch 53/200, train:, losses=0.1846, top1=91.8111, 0=92.9556, 1=95.8444, 2=88.6667, 3=83.8000, 4=92.5111, 5=85.7778, 6=93.7778, 7=94.1333, 8=95.8222, 9=94.8222, val:, losses=0.4759, top1=85.3800, 0=94.2000, 1=90.2000, 2=88.0000, 3=73.4000, 4=79.8000, 5=82.8000, 6=78.0000, 7=86.0000, 8=92.6000, 9=88.8000, test:, losses=0.4758, top1=85.5000, 0=95.5000, 1=92.3000, 2=86.8000, 3=76.4000, 4=77.9000, 5=85.7000, 6=74.6000, 7=84.8000, 8=92.5000, 9=88.5000, 48.0s 44.6m/2.8h
Epoch: [54]
epoch 54/200, train:, losses=0.1779, top1=92.1178, 0=93.1111, 1=96.0667, 2=89.8667, 3=84.9556, 4=92.5556, 5=86.2444, 6=94.2667, 7=94.0222, 8=95.4889, 9=94.6000, val:, losses=0.4724, top1=85.7000, 0=83.4000, 1=91.6000, 2=76.8000, 3=80.4000, 4=91.4000, 5=83.8000, 6=88.2000, 7=81.2000, 8=94.0000, 9=86.2000, test:, losses=0.4807, top1=85.5300, 0=84.8000, 1=91.1000, 2=73.9000, 3=82.9000, 4=91.4000, 5=85.4000, 6=85.9000, 7=79.8000, 8=93.7000, 9=86.4000, 50.4s 45.4m/2.8h
Epoch: [55]
epoch 55/200, train:, losses=0.1794, top1=91.9333, 0=92.3556, 1=95.9333, 2=89.5556, 3=85.2444, 4=91.8667, 5=86.2222, 6=94.2667, 7=93.6667, 8=95.1333, 9=95.0889, val:, losses=0.4434, top1=86.2800, 0=86.2000, 1=98.6000, 2=82.6000, 3=80.4000, 4=87.8000, 5=76.4000, 6=88.0000, 7=88.8000, 8=93.0000, 9=81.0000, test:, losses=0.4503, top1=86.3600, 0=87.8000, 1=98.6000, 2=82.1000, 3=78.0000, 4=87.3000, 5=80.6000, 6=86.4000, 7=89.6000, 8=93.5000, 9=79.7000, 49.8s 46.3m/2.8h
Epoch: [56]
epoch 56/200, train:, losses=0.1752, top1=92.1600, 0=93.5111, 1=96.5333, 2=89.2222, 3=84.8667, 4=92.4222, 5=86.0889, 6=94.0667, 7=94.1333, 8=95.3111, 9=95.4444, val:, losses=0.4445, top1=86.2400, 0=87.0000, 1=91.4000, 2=83.8000, 3=64.2000, 4=92.2000, 5=79.2000, 6=90.6000, 7=90.2000, 8=90.2000, 9=93.6000, test:, losses=0.4388, top1=86.8600, 0=87.9000, 1=91.3000, 2=84.3000, 3=65.3000, 4=91.3000, 5=81.1000, 6=92.3000, 7=89.6000, 8=90.9000, 9=94.6000, 49.8s 47.1m/2.8h
Epoch: [57]
epoch 57/200, train:, losses=0.1789, top1=92.0044, 0=92.6889, 1=96.0444, 2=89.6000, 3=85.5111, 4=91.9556, 5=86.5556, 6=93.7333, 7=94.0444, 8=95.2889, 9=94.6222, val:, losses=0.4749, top1=86.0200, 0=90.0000, 1=95.4000, 2=76.4000, 3=72.8000, 4=91.4000, 5=75.2000, 6=91.2000, 7=80.4000, 8=92.2000, 9=95.2000, test:, losses=0.5034, top1=85.5300, 0=91.6000, 1=95.8000, 2=72.9000, 3=70.0000, 4=92.6000, 5=78.0000, 6=91.5000, 7=76.6000, 8=91.4000, 9=94.9000, 49.8s 47.9m/2.8h
Epoch: [58]
epoch 58/200, train:, losses=0.1731, top1=92.2000, 0=92.8000, 1=96.0889, 2=89.7111, 3=85.7333, 4=92.2667, 5=87.0667, 6=94.1333, 7=93.8222, 8=95.4444, 9=94.9333, val:, losses=0.4270, top1=86.2600, 0=77.2000, 1=89.8000, 2=85.0000, 3=81.6000, 4=88.2000, 5=80.4000, 6=87.2000, 7=87.2000, 8=95.8000, 9=90.2000, test:, losses=0.4186, top1=86.7100, 0=76.3000, 1=89.3000, 2=83.9000, 3=82.9000, 4=89.9000, 5=80.4000, 6=87.2000, 7=89.1000, 8=97.0000, 9=91.1000, 52.3s 48.8m/2.8h
Epoch: [59]
epoch 59/200, train:, losses=0.1746, top1=92.1000, 0=92.3778, 1=96.5333, 2=89.6444, 3=85.1778, 4=91.7556, 5=87.2000, 6=94.2667, 7=93.9111, 8=95.2444, 9=94.8889, val:, losses=0.4577, top1=85.4200, 0=93.4000, 1=94.4000, 2=80.4000, 3=75.2000, 4=75.4000, 5=72.0000, 6=91.0000, 7=87.0000, 8=95.4000, 9=90.0000, test:, losses=0.4489, top1=86.4100, 0=93.6000, 1=94.3000, 2=81.7000, 3=77.7000, 4=76.6000, 5=77.5000, 6=91.4000, 7=87.5000, 8=93.4000, 9=90.4000, 51.8s 49.7m/2.8h
Epoch: [60]
epoch 60/200, train:, losses=0.1686, top1=92.5133, 0=93.2222, 1=96.2667, 2=89.8000, 3=85.8667, 4=92.7556, 5=87.2222, 6=94.6222, 7=94.4667, 8=95.6444, 9=95.2667, val:, losses=0.5896, top1=83.4400, 0=87.6000, 1=94.4000, 2=69.8000, 3=67.8000, 4=61.0000, 5=89.4000, 6=95.6000, 7=88.4000, 8=89.2000, 9=91.2000, test:, losses=0.5748, top1=83.8000, 0=87.7000, 1=95.6000, 2=68.5000, 3=70.4000, 4=62.7000, 5=89.5000, 6=95.5000, 7=88.9000, 8=89.0000, 9=90.2000, 51.5s 50.5m/2.8h
Epoch: [61]
epoch 61/200, train:, losses=0.1710, top1=92.4067, 0=93.0000, 1=96.2667, 2=89.6889, 3=85.4444, 4=92.6889, 5=86.8222, 6=94.7111, 7=94.2667, 8=95.5333, 9=95.6444, val:, losses=0.4589, top1=86.1000, 0=75.8000, 1=90.8000, 2=84.2000, 3=85.2000, 4=87.0000, 5=76.4000, 6=91.0000, 7=81.0000, 8=93.2000, 9=96.4000, test:, losses=0.4513, top1=86.2400, 0=77.9000, 1=92.8000, 2=81.1000, 3=83.4000, 4=88.1000, 5=77.2000, 6=89.1000, 7=81.5000, 8=94.3000, 9=97.0000, 51.6s 51.4m/2.8h
Epoch: [62]
epoch 62/200, train:, losses=0.1723, top1=92.3444, 0=93.7111, 1=96.0444, 2=89.5111, 3=85.2222, 4=92.6667, 5=86.9333, 6=94.2222, 7=93.6889, 8=96.0444, 9=95.4000, val:, losses=0.5450, top1=84.0400, 0=89.6000, 1=97.6000, 2=79.2000, 3=88.6000, 4=88.4000, 5=74.4000, 6=78.0000, 7=80.6000, 8=89.2000, 9=74.8000, test:, losses=0.5482, top1=83.8600, 0=89.5000, 1=97.8000, 2=77.4000, 3=90.8000, 4=88.3000, 5=75.4000, 6=75.9000, 7=81.5000, 8=89.7000, 9=72.3000, 52.1s 52.2m/2.8h
Epoch: [63]
epoch 63/200, train:, losses=0.1707, top1=92.4689, 0=92.9111, 1=96.2000, 2=90.2667, 3=86.4667, 4=92.7556, 5=87.1111, 6=94.6889, 7=94.1111, 8=95.4667, 9=94.7111, val:, losses=0.4101, top1=87.3200, 0=89.4000, 1=90.0000, 2=83.2000, 3=74.0000, 4=93.6000, 5=83.4000, 6=79.6000, 7=94.0000, 8=91.2000, 9=94.8000, test:, losses=0.4277, top1=86.7400, 0=86.8000, 1=91.5000, 2=81.5000, 3=74.4000, 4=93.4000, 5=83.0000, 6=77.3000, 7=93.7000, 8=91.1000, 9=94.7000, 50.6s 53.1m/2.8h
Epoch: [64]
epoch 64/200, train:, losses=0.1651, top1=92.6511, 0=93.5111, 1=96.7333, 2=89.7556, 3=86.2667, 4=93.0667, 5=86.7778, 6=94.3778, 7=95.0222, 8=95.3778, 9=95.6222, val:, losses=0.4151, top1=87.4600, 0=91.2000, 1=89.0000, 2=81.6000, 3=75.6000, 4=86.0000, 5=84.0000, 6=90.8000, 7=93.8000, 8=89.4000, 9=93.2000, test:, losses=0.4123, top1=87.4100, 0=89.2000, 1=91.9000, 2=79.9000, 3=77.2000, 4=86.8000, 5=83.5000, 6=91.2000, 7=91.2000, 8=89.2000, 9=94.0000, 50.9s 53.9m/2.8h
Epoch: [65]
epoch 65/200, train:, losses=0.1685, top1=92.3400, 0=92.9556, 1=96.2000, 2=89.7333, 3=85.7556, 4=93.2667, 5=86.7778, 6=94.1111, 7=94.4667, 8=95.2444, 9=94.8889, val:, losses=0.4345, top1=86.6200, 0=92.0000, 1=89.8000, 2=75.6000, 3=68.4000, 4=91.6000, 5=77.4000, 6=89.2000, 7=94.0000, 8=96.4000, 9=91.8000, test:, losses=0.4588, top1=86.3400, 0=93.4000, 1=88.7000, 2=76.5000, 3=65.2000, 4=92.1000, 5=78.0000, 6=89.5000, 7=93.7000, 8=94.8000, 9=91.5000, 50.0s 54.8m/2.8h
Epoch: [66]
epoch 66/200, train:, losses=0.1699, top1=92.3756, 0=93.1111, 1=95.7556, 2=89.4889, 3=86.0889, 4=93.2667, 5=86.4889, 6=94.1778, 7=94.4444, 8=95.9333, 9=95.0000, val:, losses=0.5726, top1=83.8600, 0=94.6000, 1=93.8000, 2=90.4000, 3=48.0000, 4=80.4000, 5=70.8000, 6=92.8000, 7=91.8000, 8=94.8000, 9=81.2000, test:, losses=0.5968, top1=83.3500, 0=94.6000, 1=93.2000, 2=90.7000, 3=45.3000, 4=82.2000, 5=72.8000, 6=92.7000, 7=90.5000, 8=94.3000, 9=77.2000, 51.4s 55.6m/2.8h
Epoch: [67]
epoch 67/200, train:, losses=0.1660, top1=92.5178, 0=92.9556, 1=96.4444, 2=89.8444, 3=85.6667, 4=92.5333, 5=87.3333, 6=94.5556, 7=94.6000, 8=95.7778, 9=95.4667, val:, losses=0.4700, top1=85.4600, 0=89.2000, 1=81.2000, 2=81.2000, 3=63.2000, 4=83.2000, 5=83.2000, 6=95.2000, 7=95.0000, 8=89.2000, 9=94.0000, test:, losses=0.4634, top1=85.8100, 0=88.6000, 1=84.4000, 2=79.4000, 3=65.7000, 4=85.4000, 5=84.9000, 6=94.2000, 7=93.9000, 8=88.3000, 9=93.3000, 49.9s 56.5m/2.8h
Epoch: [68]
epoch 68/200, train:, losses=0.1628, top1=92.7289, 0=93.3556, 1=96.5333, 2=90.2667, 3=85.9778, 4=92.8667, 5=87.4444, 6=95.1778, 7=94.6889, 8=95.2667, 9=95.7111, val:, losses=0.3743, top1=87.6600, 0=88.6000, 1=87.4000, 2=90.6000, 3=75.8000, 4=85.0000, 5=78.6000, 6=88.2000, 7=92.4000, 8=95.4000, 9=94.6000, test:, losses=0.3868, top1=87.9400, 0=87.7000, 1=90.3000, 2=88.2000, 3=79.7000, 4=85.9000, 5=78.4000, 6=88.8000, 7=92.0000, 8=94.3000, 9=94.1000, 50.1s 57.3m/2.8h
Epoch: [69]
epoch 69/200, train:, losses=0.1667, top1=92.5067, 0=93.3333, 1=96.3556, 2=90.2889, 3=86.5556, 4=92.4222, 5=87.0444, 6=94.4667, 7=93.8222, 8=95.3556, 9=95.4222, val:, losses=0.6189, top1=83.0400, 0=81.0000, 1=85.6000, 2=92.8000, 3=65.8000, 4=90.2000, 5=63.0000, 6=91.0000, 7=74.0000, 8=93.6000, 9=93.4000, test:, losses=0.6213, top1=83.0400, 0=81.7000, 1=87.7000, 2=93.4000, 3=63.7000, 4=91.5000, 5=60.9000, 6=90.2000, 7=73.8000, 8=93.7000, 9=93.8000, 48.4s 58.1m/2.8h
Epoch: [70]
epoch 70/200, train:, losses=0.1632, top1=92.7178, 0=93.2222, 1=96.0000, 2=89.8222, 3=86.6667, 4=93.8000, 5=88.1778, 6=94.2444, 7=94.2222, 8=95.7111, 9=95.3111, val:, losses=0.4642, top1=85.7000, 0=92.8000, 1=97.0000, 2=74.8000, 3=87.6000, 4=83.2000, 5=68.4000, 6=81.2000, 7=91.8000, 8=91.4000, 9=88.8000, test:, losses=0.4503, top1=86.4300, 0=93.4000, 1=96.3000, 2=72.3000, 3=90.3000, 4=83.6000, 5=73.9000, 6=81.9000, 7=93.8000, 8=90.5000, 9=88.3000, 49.2s 58.9m/2.8h
Epoch: [71]
epoch 71/200, train:, losses=0.1641, top1=92.6467, 0=93.7111, 1=96.5778, 2=90.2889, 3=86.4000, 4=92.5556, 5=87.3556, 6=94.4444, 7=94.0444, 8=95.6222, 9=95.4667, val:, losses=0.5549, top1=84.0800, 0=80.8000, 1=90.8000, 2=73.0000, 3=71.4000, 4=92.8000, 5=81.2000, 6=92.8000, 7=71.8000, 8=95.4000, 9=90.8000, test:, losses=0.5662, top1=83.5800, 0=79.9000, 1=92.5000, 2=71.4000, 3=67.9000, 4=91.2000, 5=82.3000, 6=93.2000, 7=68.9000, 8=95.0000, 9=93.5000, 50.0s 59.8m/2.8h
Epoch: [72]
epoch 72/200, train:, losses=0.1594, top1=92.9489, 0=93.7111, 1=96.2667, 2=90.4444, 3=86.7333, 4=93.3556, 5=88.4222, 6=94.5778, 7=94.6667, 8=95.7778, 9=95.5333, val:, losses=0.5286, top1=84.7000, 0=91.6000, 1=93.2000, 2=82.8000, 3=71.8000, 4=63.4000, 5=87.8000, 6=85.2000, 7=91.2000, 8=86.4000, 9=93.6000, test:, losses=0.5038, top1=85.7300, 0=92.6000, 1=95.1000, 2=86.9000, 3=73.8000, 4=65.5000, 5=88.8000, 6=85.2000, 7=92.0000, 8=84.7000, 9=92.7000, 50.6s 1.0h/2.8h
Epoch: [73]
epoch 73/200, train:, losses=0.1641, top1=92.5244, 0=93.3778, 1=95.9111, 2=90.2444, 3=86.1333, 4=92.7333, 5=87.6000, 6=94.5556, 7=94.1111, 8=95.4667, 9=95.1111, val:, losses=0.4311, top1=86.6000, 0=82.6000, 1=94.8000, 2=82.2000, 3=76.2000, 4=85.6000, 5=75.2000, 6=92.6000, 7=91.0000, 8=93.8000, 9=92.0000, test:, losses=0.4503, top1=86.6500, 0=82.3000, 1=93.5000, 2=79.8000, 3=75.3000, 4=88.5000, 5=76.8000, 6=92.8000, 7=91.3000, 8=95.1000, 9=91.1000, 49.9s 1.0h/2.8h
Epoch: [74]
epoch 74/200, train:, losses=0.1622, top1=92.7644, 0=93.3333, 1=96.3778, 2=90.8444, 3=86.7333, 4=93.0889, 5=87.6889, 6=94.4222, 7=94.1111, 8=95.8889, 9=95.1556, val:, losses=0.4312, top1=87.1200, 0=91.2000, 1=96.4000, 2=87.2000, 3=65.2000, 4=86.6000, 5=82.8000, 6=91.8000, 7=88.4000, 8=88.6000, 9=93.0000, test:, losses=0.3947, top1=87.7200, 0=91.2000, 1=96.2000, 2=88.7000, 3=66.2000, 4=85.3000, 5=82.4000, 6=92.4000, 7=90.7000, 8=90.1000, 9=94.0000, 50.6s 1.0h/2.8h
Epoch: [75]
epoch 75/200, train:, losses=0.1634, top1=92.7089, 0=93.3556, 1=96.1556, 2=90.2000, 3=86.7333, 4=92.6444, 5=87.5333, 6=94.4000, 7=94.4667, 8=95.8889, 9=95.7111, val:, losses=0.6412, top1=83.4200, 0=60.4000, 1=93.2000, 2=86.4000, 3=61.2000, 4=94.8000, 5=79.2000, 6=95.4000, 7=82.6000, 8=88.2000, 9=92.8000, test:, losses=0.5851, top1=83.8300, 0=57.2000, 1=93.8000, 2=86.3000, 3=63.6000, 4=93.5000, 5=79.5000, 6=96.4000, 7=83.7000, 8=89.2000, 9=95.1000, 49.2s 1.1h/2.8h
Epoch: [76]
epoch 76/200, train:, losses=0.1560, top1=93.0378, 0=93.7778, 1=96.2667, 2=90.4667, 3=86.9778, 4=93.4444, 5=88.0889, 6=94.8444, 7=94.9111, 8=96.1111, 9=95.4889, val:, losses=0.4371, top1=86.6400, 0=79.4000, 1=91.4000, 2=80.6000, 3=74.4000, 4=92.0000, 5=78.8000, 6=93.4000, 7=93.0000, 8=97.0000, 9=86.4000, test:, losses=0.4290, top1=87.0100, 0=79.2000, 1=92.1000, 2=78.9000, 3=76.9000, 4=92.5000, 5=80.3000, 6=91.4000, 7=93.9000, 8=96.8000, 9=88.1000, 50.1s 1.1h/2.8h
Epoch: [77]
epoch 77/200, train:, losses=0.1575, top1=93.0200, 0=94.0222, 1=96.9556, 2=90.6000, 3=87.3111, 4=93.2222, 5=87.7111, 6=94.0000, 7=94.8222, 8=95.9556, 9=95.6000, val:, losses=0.4365, top1=86.4200, 0=93.8000, 1=81.2000, 2=77.6000, 3=68.4000, 4=91.0000, 5=79.8000, 6=91.2000, 7=94.2000, 8=93.6000, 9=93.4000, test:, losses=0.4556, top1=86.9300, 0=94.0000, 1=83.5000, 2=76.3000, 3=68.4000, 4=90.9000, 5=81.5000, 6=93.4000, 7=93.7000, 8=93.2000, 9=94.4000, 50.4s 1.1h/2.8h
Epoch: [78]
epoch 78/200, train:, losses=0.1595, top1=92.8689, 0=93.4667, 1=96.4000, 2=90.2889, 3=86.4444, 4=93.4444, 5=87.9778, 6=94.6222, 7=94.0667, 8=96.5333, 9=95.4444, val:, losses=0.4403, top1=87.1400, 0=81.6000, 1=93.8000, 2=82.0000, 3=87.2000, 4=87.6000, 5=71.2000, 6=92.2000, 7=87.8000, 8=94.6000, 9=93.4000, test:, losses=0.4267, top1=87.6100, 0=84.7000, 1=95.4000, 2=78.8000, 3=87.6000, 4=88.4000, 5=71.9000, 6=91.7000, 7=89.1000, 8=95.7000, 9=92.8000, 51.5s 1.1h/2.8h
Epoch: [79]
epoch 79/200, train:, losses=0.1593, top1=92.8444, 0=93.3778, 1=96.2667, 2=91.0222, 3=86.4222, 4=93.0000, 5=87.9111, 6=94.8667, 7=94.5556, 8=95.5778, 9=95.4444, val:, losses=0.5996, top1=83.5400, 0=86.2000, 1=94.4000, 2=71.2000, 3=87.4000, 4=82.8000, 5=81.4000, 6=85.6000, 7=85.4000, 8=67.2000, 9=93.8000, test:, losses=0.6013, top1=83.2600, 0=87.3000, 1=93.9000, 2=70.8000, 3=86.3000, 4=81.3000, 5=82.7000, 6=84.6000, 7=84.6000, 8=67.3000, 9=93.8000, 51.3s 1.1h/2.8h
Epoch: [80]
epoch 80/200, train:, losses=0.1537, top1=93.0111, 0=94.1778, 1=96.6667, 2=90.5778, 3=86.8667, 4=93.2667, 5=87.7333, 6=94.7556, 7=94.4889, 8=95.8222, 9=95.7556, val:, losses=0.4949, top1=84.9200, 0=84.8000, 1=97.6000, 2=87.8000, 3=82.0000, 4=83.6000, 5=61.8000, 6=84.0000, 7=92.2000, 8=84.4000, 9=91.0000, test:, losses=0.4860, top1=85.3900, 0=86.1000, 1=97.4000, 2=88.5000, 3=82.6000, 4=83.3000, 5=63.1000, 6=84.7000, 7=92.1000, 8=84.3000, 9=91.8000, 51.1s 1.1h/2.8h
Epoch: [81]
epoch 81/200, train:, losses=0.1533, top1=93.0556, 0=93.7778, 1=96.5111, 2=90.9556, 3=87.1778, 4=92.8000, 5=88.0889, 6=95.0667, 7=94.8222, 8=96.0000, 9=95.3556, val:, losses=0.4695, top1=85.6600, 0=72.2000, 1=95.6000, 2=86.6000, 3=74.4000, 4=70.4000, 5=83.0000, 6=94.6000, 7=93.8000, 8=94.4000, 9=91.6000, test:, losses=0.4627, top1=85.8200, 0=70.1000, 1=96.1000, 2=85.9000, 3=75.4000, 4=70.7000, 5=83.6000, 6=94.9000, 7=93.7000, 8=95.7000, 9=92.1000, 50.8s 1.1h/2.8h
Epoch: [82]
epoch 82/200, train:, losses=0.1575, top1=93.0022, 0=93.2889, 1=96.7111, 2=90.1556, 3=86.9778, 4=93.5778, 5=88.8222, 6=94.7778, 7=94.4889, 8=95.5333, 9=95.6889, val:, losses=0.5116, top1=85.5600, 0=72.2000, 1=87.6000, 2=91.2000, 3=67.2000, 4=91.0000, 5=83.6000, 6=81.2000, 7=92.2000, 8=97.0000, 9=92.4000, test:, losses=0.5137, top1=85.3300, 0=70.2000, 1=89.8000, 2=89.7000, 3=64.9000, 4=90.9000, 5=82.2000, 6=83.0000, 7=91.5000, 8=97.2000, 9=93.9000, 51.9s 1.2h/2.8h
Epoch: [83]
epoch 83/200, train:, losses=0.1555, top1=92.9933, 0=94.0889, 1=96.6222, 2=91.1333, 3=86.6444, 4=92.6000, 5=87.9333, 6=94.9111, 7=94.4667, 8=95.6889, 9=95.8444, val:, losses=0.5106, top1=84.9400, 0=82.8000, 1=96.2000, 2=70.8000, 3=77.2000, 4=86.6000, 5=85.2000, 6=71.2000, 7=94.4000, 8=92.4000, 9=92.6000, test:, losses=0.5269, top1=84.8000, 0=83.1000, 1=95.5000, 2=68.0000, 3=75.9000, 4=88.0000, 5=88.7000, 6=71.5000, 7=93.4000, 8=92.6000, 9=91.3000, 51.5s 1.2h/2.8h
Epoch: [84]
epoch 84/200, train:, losses=0.1567, top1=92.9067, 0=94.1778, 1=96.5333, 2=90.7333, 3=86.4000, 4=92.7333, 5=88.3333, 6=94.5333, 7=94.2222, 8=96.2222, 9=95.1778, val:, losses=0.4805, top1=86.1600, 0=89.0000, 1=90.2000, 2=90.2000, 3=76.2000, 4=71.4000, 5=87.4000, 6=83.0000, 7=86.8000, 8=96.2000, 9=91.2000, test:, losses=0.4787, top1=85.7300, 0=85.3000, 1=91.3000, 2=89.2000, 3=79.0000, 4=71.1000, 5=86.2000, 6=82.1000, 7=88.3000, 8=94.9000, 9=89.9000, 51.7s 1.2h/2.8h
Epoch: [85]
epoch 85/200, train:, losses=0.1541, top1=93.0289, 0=93.5111, 1=96.6444, 2=90.2000, 3=86.5333, 4=93.2889, 5=88.4667, 6=95.0222, 7=94.5778, 8=96.1778, 9=95.8667, val:, losses=0.4837, top1=85.4600, 0=81.6000, 1=87.8000, 2=86.8000, 3=86.2000, 4=83.4000, 5=71.8000, 6=76.8000, 7=90.4000, 8=93.2000, 9=96.6000, test:, losses=0.4832, top1=85.5500, 0=79.3000, 1=90.7000, 2=85.6000, 3=84.3000, 4=84.6000, 5=74.2000, 6=77.4000, 7=90.2000, 8=92.7000, 9=96.5000, 51.4s 1.2h/2.8h
Epoch: [86]
epoch 86/200, train:, losses=0.1501, top1=93.2800, 0=94.1333, 1=96.5333, 2=91.5556, 3=87.6889, 4=94.0222, 5=87.5333, 6=94.9333, 7=94.6000, 8=96.1556, 9=95.6444, val:, losses=0.5416, top1=84.4800, 0=76.8000, 1=97.0000, 2=86.6000, 3=46.0000, 4=92.4000, 5=85.8000, 6=87.0000, 7=94.4000, 8=92.8000, 9=86.0000, test:, losses=0.5404, top1=84.4200, 0=81.4000, 1=96.6000, 2=83.7000, 3=44.7000, 4=92.0000, 5=87.1000, 6=87.0000, 7=93.7000, 8=92.5000, 9=85.5000, 51.2s 1.2h/2.8h
Epoch: [87]
epoch 87/200, train:, losses=0.1552, top1=93.1244, 0=93.6222, 1=96.8222, 2=91.2000, 3=86.8444, 4=93.8222, 5=88.0000, 6=94.9111, 7=94.8222, 8=96.0667, 9=95.1333, val:, losses=0.4351, top1=87.3000, 0=90.2000, 1=93.0000, 2=80.6000, 3=72.4000, 4=91.0000, 5=70.6000, 6=94.2000, 7=94.6000, 8=95.8000, 9=90.6000, test:, losses=0.4528, top1=87.0500, 0=89.2000, 1=94.1000, 2=78.7000, 3=71.6000, 4=91.6000, 5=71.4000, 6=94.1000, 7=94.3000, 8=94.1000, 9=91.4000, 51.3s 1.2h/2.8h
Epoch: [88]
epoch 88/200, train:, losses=0.1541, top1=93.0156, 0=93.8000, 1=96.3333, 2=90.7778, 3=87.0444, 4=93.2667, 5=88.6000, 6=94.9111, 7=94.5111, 8=95.6222, 9=95.2889, val:, losses=0.4549, top1=86.8200, 0=88.6000, 1=91.2000, 2=86.0000, 3=87.4000, 4=82.4000, 5=76.2000, 6=91.0000, 7=83.0000, 8=90.4000, 9=92.0000, test:, losses=0.4462, top1=86.4900, 0=87.9000, 1=91.7000, 2=86.5000, 3=88.1000, 4=82.0000, 5=76.4000, 6=88.9000, 7=82.4000, 8=89.7000, 9=91.3000, 52.4s 1.2h/2.8h
Epoch: [89]
epoch 89/200, train:, losses=0.1494, top1=93.4822, 0=94.4222, 1=96.8444, 2=91.5333, 3=88.0222, 4=93.5111, 5=88.8889, 6=94.9333, 7=94.4667, 8=96.3556, 9=95.8444, val:, losses=0.4312, top1=87.3800, 0=83.8000, 1=93.2000, 2=80.0000, 3=70.8000, 4=95.2000, 5=79.0000, 6=88.0000, 7=93.8000, 8=94.4000, 9=95.6000, test:, losses=0.4490, top1=87.3400, 0=85.2000, 1=93.6000, 2=81.6000, 3=68.5000, 4=96.5000, 5=78.6000, 6=87.3000, 7=93.6000, 8=94.1000, 9=94.4000, 49.8s 1.3h/2.8h
Epoch: [90]
epoch 90/200, train:, losses=0.1498, top1=93.3156, 0=94.1778, 1=96.8222, 2=90.7333, 3=86.9333, 4=93.7556, 5=88.5333, 6=94.7778, 7=94.6000, 8=96.8444, 9=95.9778, val:, losses=0.4336, top1=87.4000, 0=91.2000, 1=96.6000, 2=87.8000, 3=78.0000, 4=90.0000, 5=71.6000, 6=86.2000, 7=94.0000, 8=90.6000, 9=88.0000, test:, losses=0.4366, top1=87.2100, 0=90.5000, 1=96.4000, 2=85.0000, 3=76.5000, 4=91.8000, 5=74.1000, 6=85.8000, 7=94.3000, 8=91.6000, 9=86.1000, 50.9s 1.3h/2.8h
Epoch: [91]
epoch 91/200, train:, losses=0.1480, top1=93.3200, 0=93.7111, 1=96.8889, 2=91.0667, 3=87.6000, 4=93.3778, 5=88.7333, 6=95.0889, 7=94.6444, 8=96.2000, 9=95.8889, val:, losses=0.4030, top1=87.7200, 0=86.2000, 1=97.2000, 2=90.4000, 3=76.0000, 4=91.4000, 5=80.8000, 6=88.6000, 7=89.0000, 8=89.6000, 9=88.0000, test:, losses=0.3971, top1=87.8100, 0=84.7000, 1=97.4000, 2=90.3000, 3=77.0000, 4=91.6000, 5=79.3000, 6=90.3000, 7=88.3000, 8=90.2000, 9=89.0000, 50.1s 1.3h/2.8h
Epoch: [92]
epoch 92/200, train:, losses=0.1560, top1=92.9889, 0=93.8667, 1=96.2667, 2=90.2444, 3=87.4667, 4=93.3778, 5=87.7111, 6=94.8667, 7=94.7333, 8=96.1111, 9=95.2444, val:, losses=0.4611, top1=85.9200, 0=89.6000, 1=93.0000, 2=82.6000, 3=45.2000, 4=86.2000, 5=90.2000, 6=93.2000, 7=92.8000, 8=94.2000, 9=92.2000, test:, losses=0.4611, top1=86.5700, 0=91.6000, 1=93.9000, 2=81.7000, 3=46.1000, 4=87.0000, 5=90.0000, 6=94.8000, 7=93.0000, 8=94.3000, 9=93.3000, 49.9s 1.3h/2.8h
Epoch: [93]
epoch 93/200, train:, losses=0.1522, top1=93.1356, 0=93.6222, 1=96.8444, 2=91.0000, 3=87.2000, 4=93.1333, 5=88.3778, 6=94.7111, 7=94.6444, 8=96.2000, 9=95.6222, val:, losses=0.4079, top1=87.7400, 0=88.6000, 1=92.0000, 2=80.6000, 3=85.0000, 4=89.2000, 5=76.6000, 6=84.0000, 7=93.6000, 8=94.6000, 9=93.2000, test:, losses=0.3865, top1=88.1400, 0=90.8000, 1=94.4000, 2=78.5000, 3=85.6000, 4=90.1000, 5=76.9000, 6=83.6000, 7=93.2000, 8=94.8000, 9=93.5000, 49.1s 1.3h/2.8h
Epoch: [94]
epoch 94/200, train:, losses=0.1533, top1=93.1800, 0=93.7111, 1=96.5556, 2=91.4444, 3=87.3333, 4=93.3111, 5=88.5333, 6=95.1333, 7=94.8000, 8=95.9111, 9=95.0667, val:, losses=0.5570, top1=84.4800, 0=82.6000, 1=77.8000, 2=81.0000, 3=65.8000, 4=90.2000, 5=74.6000, 6=84.0000, 7=95.8000, 8=97.6000, 9=95.4000, test:, losses=0.5343, top1=84.9800, 0=81.9000, 1=82.4000, 2=77.0000, 3=66.1000, 4=91.6000, 5=74.4000, 6=85.5000, 7=96.0000, 8=97.7000, 9=97.2000, 49.9s 1.3h/2.8h
Epoch: [95]
epoch 95/200, train:, losses=0.1521, top1=93.2200, 0=93.7778, 1=96.4444, 2=90.7556, 3=87.5556, 4=93.8222, 5=88.1778, 6=95.3778, 7=94.7333, 8=95.8444, 9=95.7111, val:, losses=0.4532, top1=86.2400, 0=94.2000, 1=96.4000, 2=76.0000, 3=69.8000, 4=95.2000, 5=87.0000, 6=89.0000, 7=87.6000, 8=79.0000, 9=88.2000, test:, losses=0.4722, top1=86.2700, 0=95.6000, 1=95.8000, 2=71.8000, 3=70.4000, 4=96.6000, 5=86.6000, 6=87.8000, 7=88.6000, 8=80.4000, 9=89.1000, 51.0s 1.3h/2.8h
Epoch: [96]
epoch 96/200, train:, losses=0.1507, top1=93.2244, 0=93.7778, 1=96.6889, 2=90.9778, 3=87.7333, 4=93.8222, 5=88.0222, 6=94.9333, 7=94.8000, 8=96.0444, 9=95.4444, val:, losses=0.6274, top1=83.0600, 0=72.2000, 1=69.6000, 2=83.0000, 3=68.4000, 4=94.6000, 5=71.2000, 6=90.8000, 7=85.8000, 8=98.2000, 9=96.8000, test:, losses=0.6287, top1=83.4100, 0=72.0000, 1=74.3000, 2=80.0000, 3=69.8000, 4=95.0000, 5=71.3000, 6=91.9000, 7=84.7000, 8=97.6000, 9=97.5000, 49.3s 1.3h/2.8h
Epoch: [97]
epoch 97/200, train:, losses=0.1478, top1=93.4644, 0=94.3111, 1=96.8000, 2=91.2000, 3=87.8667, 4=93.8444, 5=89.2000, 6=94.7778, 7=94.9111, 8=95.9778, 9=95.7556, val:, losses=0.4328, top1=87.5600, 0=89.0000, 1=86.6000, 2=87.0000, 3=82.0000, 4=92.0000, 5=80.8000, 6=85.2000, 7=86.0000, 8=90.6000, 9=96.4000, test:, losses=0.4041, top1=87.7800, 0=89.7000, 1=90.6000, 2=86.7000, 3=80.1000, 4=90.9000, 5=81.2000, 6=84.1000, 7=86.4000, 8=91.3000, 9=96.8000, 49.0s 1.4h/2.8h
Epoch: [98]
epoch 98/200, train:, losses=0.1437, top1=93.5667, 0=93.9111, 1=96.8222, 2=91.9333, 3=87.9778, 4=93.5778, 5=89.1333, 6=95.5333, 7=94.8667, 8=96.1333, 9=95.7778, val:, losses=0.5586, top1=84.3200, 0=93.4000, 1=80.0000, 2=77.6000, 3=59.6000, 4=86.0000, 5=86.8000, 6=76.6000, 7=95.4000, 8=90.0000, 9=97.8000, test:, losses=0.5578, top1=84.3700, 0=93.7000, 1=84.3000, 2=75.6000, 3=59.6000, 4=86.4000, 5=88.9000, 6=74.6000, 7=94.4000, 8=88.3000, 9=97.9000, 49.1s 1.4h/2.8h
Epoch: [99]
epoch 99/200, train:, losses=0.1494, top1=93.3333, 0=94.0667, 1=96.6222, 2=91.0444, 3=87.7556, 4=93.7556, 5=88.0000, 6=94.9778, 7=95.3556, 8=95.7333, 9=96.0222, val:, losses=0.4248, top1=87.1200, 0=90.6000, 1=91.6000, 2=82.8000, 3=71.4000, 4=95.8000, 5=87.6000, 6=87.4000, 7=79.4000, 8=93.0000, 9=91.6000, test:, losses=0.4537, top1=86.8800, 0=90.5000, 1=93.0000, 2=81.6000, 3=73.4000, 4=94.8000, 5=86.1000, 6=85.4000, 7=80.0000, 8=93.6000, 9=90.4000, 50.7s 1.4h/2.8h
Epoch: [100]
epoch 100/200, train:, losses=0.0819, top1=96.5111, 0=97.0889, 1=98.0667, 2=95.1778, 3=93.4889, 4=97.1778, 5=93.6444, 6=97.4667, 7=97.0667, 8=97.9556, 9=97.9778, val:, losses=0.2714, top1=91.6400, 0=92.2000, 1=93.8000, 2=88.8000, 3=82.2000, 4=93.6000, 5=85.8000, 6=94.6000, 7=93.6000, 8=96.4000, 9=95.4000, test:, losses=0.2798, top1=91.3500, 0=92.9000, 1=95.0000, 2=86.5000, 3=81.4000, 4=94.4000, 5=86.9000, 6=93.1000, 7=93.9000, 8=94.7000, 9=94.7000, 49.9s 1.4h/2.8h
Epoch: [101]
epoch 101/200, train:, losses=0.0601, top1=97.5467, 0=98.2000, 1=98.9111, 2=96.9333, 3=94.7333, 4=97.5556, 5=94.9556, 6=98.6889, 7=98.2889, 8=98.6889, 9=98.5111, val:, losses=0.2691, top1=91.7200, 0=92.6000, 1=94.8000, 2=89.0000, 3=84.4000, 4=93.4000, 5=84.8000, 6=93.6000, 7=94.2000, 8=95.4000, 9=95.0000, test:, losses=0.2757, top1=91.5000, 0=93.7000, 1=95.3000, 2=86.2000, 3=84.3000, 4=94.4000, 5=86.3000, 6=91.8000, 7=93.9000, 8=94.4000, 9=94.7000, 50.3s 1.4h/2.8h
Epoch: [102]
epoch 102/200, train:, losses=0.0515, top1=97.9222, 0=98.2889, 1=99.1333, 2=97.0667, 3=95.9111, 4=98.1556, 5=95.8222, 6=98.5333, 7=98.6222, 8=98.9778, 9=98.7111, val:, losses=0.2698, top1=91.9000, 0=92.4000, 1=95.6000, 2=90.6000, 3=84.0000, 4=92.4000, 5=84.8000, 6=95.4000, 7=93.2000, 8=96.4000, 9=94.2000, test:, losses=0.2728, top1=91.9200, 0=93.2000, 1=96.3000, 2=87.5000, 3=83.7000, 4=92.9000, 5=88.3000, 6=94.0000, 7=93.4000, 8=94.9000, 9=95.0000, 50.5s 1.4h/2.8h
Epoch: [103]
epoch 103/200, train:, losses=0.0458, top1=98.1533, 0=98.6000, 1=99.0000, 2=97.7556, 3=96.2222, 4=98.3111, 5=96.0000, 6=98.9556, 7=98.7556, 8=99.1111, 9=98.8222, val:, losses=0.2745, top1=91.7800, 0=92.6000, 1=95.4000, 2=90.0000, 3=82.6000, 4=92.4000, 5=85.4000, 6=95.0000, 7=94.0000, 8=96.0000, 9=94.4000, test:, losses=0.2757, top1=92.0300, 0=93.4000, 1=96.1000, 2=88.2000, 3=83.3000, 4=93.4000, 5=88.3000, 6=93.3000, 7=94.3000, 8=95.5000, 9=94.5000, 51.4s 1.4h/2.8h
Epoch: [104]
epoch 104/200, train:, losses=0.0425, top1=98.2689, 0=98.7778, 1=99.1333, 2=97.9333, 3=96.1778, 4=98.6222, 5=96.3111, 6=98.8889, 7=98.6444, 8=99.3333, 9=98.8667, val:, losses=0.2740, top1=91.9800, 0=93.4000, 1=96.2000, 2=90.4000, 3=81.4000, 4=94.6000, 5=85.8000, 6=94.6000, 7=94.0000, 8=96.2000, 9=93.2000, test:, losses=0.2812, top1=91.9700, 0=93.9000, 1=96.4000, 2=88.0000, 3=82.8000, 4=94.9000, 5=87.6000, 6=93.2000, 7=93.8000, 8=95.0000, 9=94.1000, 50.9s 1.5h/2.8h
Epoch: [105]
epoch 105/200, train:, losses=0.0391, top1=98.4289, 0=98.9111, 1=99.3778, 2=97.7111, 3=96.4444, 4=98.5778, 5=96.8889, 6=99.1111, 7=99.0000, 8=99.2889, 9=98.9778, val:, losses=0.2818, top1=92.0200, 0=92.4000, 1=96.4000, 2=90.8000, 3=84.6000, 4=93.6000, 5=82.4000, 6=95.4000, 7=94.8000, 8=96.2000, 9=93.6000, test:, losses=0.2821, top1=92.0300, 0=93.5000, 1=97.1000, 2=87.9000, 3=85.2000, 4=94.0000, 5=85.5000, 6=93.5000, 7=94.4000, 8=95.2000, 9=94.0000, 51.7s 1.5h/2.8h
Epoch: [106]
epoch 106/200, train:, losses=0.0366, top1=98.4844, 0=98.7111, 1=99.2444, 2=98.2444, 3=96.7778, 4=98.4667, 5=96.8000, 6=99.0222, 7=99.1778, 8=99.3111, 9=99.0889, val:, losses=0.2840, top1=92.0400, 0=92.8000, 1=95.6000, 2=88.8000, 3=83.6000, 4=94.8000, 5=84.4000, 6=94.8000, 7=94.4000, 8=95.6000, 9=95.6000, test:, losses=0.2891, top1=92.1800, 0=93.5000, 1=96.6000, 2=87.7000, 3=83.5000, 4=94.9000, 5=87.3000, 6=93.8000, 7=94.0000, 8=95.2000, 9=95.3000, 53.3s 1.5h/2.8h
Epoch: [107]
epoch 107/200, train:, losses=0.0347, top1=98.5333, 0=99.0000, 1=99.2889, 2=97.9778, 3=96.7111, 4=98.8000, 5=96.7778, 6=99.2222, 7=99.0000, 8=99.3333, 9=99.2222, val:, losses=0.2852, top1=91.9600, 0=92.0000, 1=96.2000, 2=91.0000, 3=84.2000, 4=95.0000, 5=82.0000, 6=94.6000, 7=94.4000, 8=96.0000, 9=94.2000, test:, losses=0.2862, top1=92.0700, 0=92.5000, 1=96.8000, 2=89.3000, 3=84.3000, 4=95.1000, 5=84.6000, 6=93.5000, 7=94.5000, 8=95.5000, 9=94.6000, 51.3s 1.5h/2.8h
Epoch: [108]
epoch 108/200, train:, losses=0.0319, top1=98.7378, 0=99.1556, 1=99.4222, 2=98.4000, 3=97.4444, 4=98.9333, 5=97.2222, 6=99.2444, 7=98.9556, 8=99.3778, 9=99.2222, val:, losses=0.2902, top1=91.8600, 0=92.8000, 1=96.6000, 2=91.0000, 3=81.8000, 4=94.2000, 5=83.8000, 6=95.4000, 7=94.0000, 8=95.8000, 9=93.2000, test:, losses=0.2936, top1=92.1700, 0=94.0000, 1=97.6000, 2=88.9000, 3=83.0000, 4=93.8000, 5=86.6000, 6=95.2000, 7=94.1000, 8=95.0000, 9=93.5000, 51.4s 1.5h/2.8h
Epoch: [109]
epoch 109/200, train:, losses=0.0302, top1=98.8022, 0=99.2000, 1=99.4667, 2=98.4889, 3=97.5333, 4=98.7778, 5=97.3333, 6=99.3556, 7=99.1778, 8=99.4444, 9=99.2444, val:, losses=0.2895, top1=92.0000, 0=92.4000, 1=97.0000, 2=89.2000, 3=81.0000, 4=95.8000, 5=86.6000, 6=94.4000, 7=94.2000, 8=95.8000, 9=93.6000, test:, losses=0.2952, top1=92.0300, 0=93.6000, 1=97.5000, 2=85.8000, 3=81.0000, 4=94.9000, 5=89.0000, 6=94.8000, 7=93.9000, 8=95.9000, 9=93.9000, 51.4s 1.5h/2.8h
Epoch: [110]
epoch 110/200, train:, losses=0.0293, top1=98.8244, 0=99.1333, 1=99.4667, 2=98.2889, 3=97.7333, 4=98.7778, 5=97.6444, 6=99.1778, 7=99.2667, 8=99.4667, 9=99.2889, val:, losses=0.2945, top1=91.8200, 0=92.2000, 1=97.8000, 2=90.8000, 3=82.8000, 4=94.4000, 5=84.2000, 6=92.6000, 7=94.2000, 8=95.8000, 9=93.4000, test:, losses=0.3010, top1=91.8300, 0=92.6000, 1=97.9000, 2=90.1000, 3=83.0000, 4=93.5000, 5=86.8000, 6=92.3000, 7=93.6000, 8=94.7000, 9=93.8000, 51.3s 1.5h/2.8h
Epoch: [111]
epoch 111/200, train:, losses=0.0288, top1=98.8556, 0=99.2667, 1=99.4667, 2=98.5556, 3=97.6000, 4=98.9556, 5=97.4222, 6=99.2444, 7=99.2000, 8=99.5556, 9=99.2889, val:, losses=0.2966, top1=92.0000, 0=92.4000, 1=96.4000, 2=90.0000, 3=81.8000, 4=94.6000, 5=85.2000, 6=94.8000, 7=94.4000, 8=95.8000, 9=94.6000, test:, losses=0.2989, top1=92.1200, 0=92.7000, 1=96.4000, 2=88.1000, 3=82.6000, 4=93.8000, 5=87.9000, 6=94.3000, 7=94.5000, 8=95.9000, 9=95.0000, 50.3s 1.6h/2.8h
Epoch: [112]
epoch 112/200, train:, losses=0.0262, top1=98.9733, 0=99.2444, 1=99.5111, 2=98.8222, 3=97.8667, 4=99.0222, 5=97.7778, 6=99.4000, 7=99.2000, 8=99.6000, 9=99.2889, val:, losses=0.2979, top1=91.9000, 0=92.0000, 1=96.4000, 2=90.6000, 3=81.0000, 4=94.8000, 5=84.8000, 6=94.2000, 7=94.2000, 8=96.2000, 9=94.8000, test:, losses=0.3004, top1=92.0600, 0=92.7000, 1=97.2000, 2=88.3000, 3=82.2000, 4=94.8000, 5=88.8000, 6=93.3000, 7=93.7000, 8=95.3000, 9=94.3000, 51.3s 1.6h/2.8h
Epoch: [113]
epoch 113/200, train:, losses=0.0252, top1=99.0222, 0=99.3333, 1=99.4000, 2=98.7333, 3=97.8222, 4=99.0889, 5=98.2000, 6=99.4444, 7=99.3556, 8=99.4889, 9=99.3556, val:, losses=0.3023, top1=92.0600, 0=92.2000, 1=96.2000, 2=88.8000, 3=83.0000, 4=94.8000, 5=85.8000, 6=95.8000, 7=93.2000, 8=95.8000, 9=95.0000, test:, losses=0.3045, top1=92.0300, 0=93.0000, 1=96.3000, 2=87.1000, 3=83.4000, 4=95.1000, 5=87.8000, 6=93.8000, 7=93.1000, 8=96.0000, 9=94.7000, 49.3s 1.6h/2.8h
Epoch: [114]
epoch 114/200, train:, losses=0.0241, top1=99.0822, 0=99.2000, 1=99.4889, 2=98.7333, 3=98.1111, 4=99.1778, 5=98.2000, 6=99.4889, 7=99.3778, 8=99.6889, 9=99.3556, val:, losses=0.3117, top1=91.9400, 0=91.4000, 1=96.8000, 2=90.6000, 3=83.6000, 4=94.8000, 5=83.8000, 6=94.4000, 7=93.8000, 8=96.4000, 9=93.8000, test:, losses=0.3088, top1=92.0900, 0=92.3000, 1=97.1000, 2=88.8000, 3=84.7000, 4=95.1000, 5=87.5000, 6=92.5000, 7=93.3000, 8=95.8000, 9=93.8000, 48.9s 1.6h/2.8h
Epoch: [115]
epoch 115/200, train:, losses=0.0233, top1=99.1156, 0=99.2000, 1=99.6222, 2=98.7333, 3=98.0444, 4=99.2889, 5=98.0444, 6=99.5111, 7=99.5333, 8=99.6889, 9=99.4889, val:, losses=0.3072, top1=91.9000, 0=92.6000, 1=96.0000, 2=90.4000, 3=81.8000, 4=93.8000, 5=85.4000, 6=94.2000, 7=93.8000, 8=96.0000, 9=95.0000, test:, losses=0.3128, top1=92.0100, 0=93.4000, 1=96.9000, 2=88.4000, 3=82.1000, 4=94.3000, 5=88.5000, 6=93.9000, 7=93.3000, 8=94.6000, 9=94.7000, 50.1s 1.6h/2.8h
Epoch: [116]
epoch 116/200, train:, losses=0.0214, top1=99.2044, 0=99.3556, 1=99.7556, 2=98.9111, 3=98.4889, 4=99.2444, 5=98.5111, 6=99.5333, 7=99.4222, 8=99.4667, 9=99.3556, val:, losses=0.3146, top1=91.9800, 0=92.6000, 1=96.0000, 2=90.6000, 3=83.0000, 4=94.0000, 5=85.4000, 6=94.6000, 7=93.0000, 8=96.6000, 9=94.0000, test:, losses=0.3194, top1=91.9700, 0=92.7000, 1=97.0000, 2=88.3000, 3=83.6000, 4=95.2000, 5=86.8000, 6=93.4000, 7=92.1000, 8=95.4000, 9=95.2000, 50.1s 1.6h/2.8h
Epoch: [117]
epoch 117/200, train:, losses=0.0219, top1=99.1467, 0=99.5111, 1=99.5778, 2=98.9111, 3=97.9778, 4=99.4667, 5=98.2667, 6=99.5556, 7=99.3333, 8=99.5111, 9=99.3556, val:, losses=0.3167, top1=92.2800, 0=92.0000, 1=96.2000, 2=90.2000, 3=81.4000, 4=95.2000, 5=86.8000, 6=95.8000, 7=93.6000, 8=97.2000, 9=94.4000, test:, losses=0.3209, top1=92.0700, 0=92.6000, 1=97.1000, 2=87.2000, 3=81.1000, 4=96.0000, 5=88.9000, 6=93.3000, 7=93.8000, 8=96.0000, 9=94.7000, 50.4s 1.6h/2.8h
Epoch: [118]
epoch 118/200, train:, losses=0.0205, top1=99.2178, 0=99.4889, 1=99.6889, 2=98.9778, 3=98.3778, 4=99.1778, 5=98.5778, 6=99.4889, 7=99.3778, 8=99.6667, 9=99.3556, val:, losses=0.3098, top1=92.0600, 0=93.0000, 1=95.8000, 2=90.4000, 3=82.2000, 4=94.0000, 5=85.4000, 6=95.0000, 7=93.4000, 8=96.8000, 9=94.6000, test:, losses=0.3110, top1=92.1800, 0=94.0000, 1=96.5000, 2=88.2000, 3=82.9000, 4=94.5000, 5=88.4000, 6=94.0000, 7=93.7000, 8=95.2000, 9=94.4000, 51.1s 1.7h/2.8h
Epoch: [119]
epoch 119/200, train:, losses=0.0198, top1=99.2178, 0=99.4000, 1=99.5333, 2=98.8889, 3=98.2000, 4=99.2222, 5=98.6222, 6=99.5778, 7=99.5333, 8=99.7333, 9=99.4667, val:, losses=0.3131, top1=92.1000, 0=92.4000, 1=96.0000, 2=90.0000, 3=83.0000, 4=94.4000, 5=83.8000, 6=95.8000, 7=94.2000, 8=96.6000, 9=94.8000, test:, losses=0.3112, top1=92.1700, 0=93.8000, 1=97.2000, 2=88.6000, 3=82.7000, 4=93.9000, 5=87.7000, 6=94.4000, 7=94.7000, 8=94.8000, 9=93.9000, 50.0s 1.7h/2.8h
Epoch: [120]
epoch 120/200, train:, losses=0.0198, top1=99.2422, 0=99.2222, 1=99.6000, 2=99.0000, 3=98.4000, 4=99.3556, 5=98.4444, 6=99.5333, 7=99.4889, 8=99.7778, 9=99.6000, val:, losses=0.3156, top1=91.8000, 0=92.4000, 1=96.2000, 2=89.6000, 3=82.8000, 4=94.6000, 5=83.2000, 6=94.8000, 7=94.0000, 8=97.0000, 9=93.4000, test:, losses=0.3186, top1=92.2800, 0=93.1000, 1=96.8000, 2=88.0000, 3=83.5000, 4=95.1000, 5=87.5000, 6=93.9000, 7=94.0000, 8=96.0000, 9=94.9000, 50.5s 1.7h/2.8h
Epoch: [121]
epoch 121/200, train:, losses=0.0176, top1=99.3778, 0=99.5778, 1=99.7111, 2=98.9111, 3=98.8222, 4=99.4222, 5=98.7333, 6=99.7778, 7=99.5556, 8=99.6889, 9=99.5778, val:, losses=0.3221, top1=92.1400, 0=92.2000, 1=96.2000, 2=90.0000, 3=82.4000, 4=94.2000, 5=85.8000, 6=95.8000, 7=94.6000, 8=96.6000, 9=93.6000, test:, losses=0.3280, top1=92.1700, 0=93.3000, 1=96.8000, 2=88.1000, 3=83.0000, 4=94.6000, 5=89.1000, 6=94.1000, 7=94.0000, 8=94.9000, 9=93.8000, 50.0s 1.7h/2.8h
Epoch: [122]
epoch 122/200, train:, losses=0.0184, top1=99.3289, 0=99.4667, 1=99.7778, 2=99.2667, 3=98.4889, 4=99.4889, 5=98.6444, 6=99.5778, 7=99.4889, 8=99.6444, 9=99.4444, val:, losses=0.3244, top1=91.8200, 0=92.2000, 1=95.6000, 2=88.4000, 3=81.4000, 4=94.6000, 5=85.8000, 6=95.2000, 7=94.0000, 8=96.8000, 9=94.2000, test:, losses=0.3287, top1=92.1400, 0=93.3000, 1=96.3000, 2=87.5000, 3=83.3000, 4=95.8000, 5=87.6000, 6=94.6000, 7=93.4000, 8=94.8000, 9=94.8000, 50.6s 1.7h/2.8h
Epoch: [123]
epoch 123/200, train:, losses=0.0170, top1=99.3556, 0=99.5556, 1=99.6889, 2=99.1778, 3=98.7778, 4=99.4222, 5=98.7556, 6=99.6000, 7=99.4667, 8=99.7333, 9=99.3778, val:, losses=0.3264, top1=91.8400, 0=92.0000, 1=95.2000, 2=90.4000, 3=80.4000, 4=95.8000, 5=84.2000, 6=95.0000, 7=93.4000, 8=96.8000, 9=95.2000, test:, losses=0.3373, top1=91.9400, 0=93.0000, 1=96.2000, 2=88.0000, 3=81.4000, 4=96.4000, 5=88.0000, 6=94.5000, 7=92.6000, 8=94.4000, 9=94.9000, 49.2s 1.7h/2.8h
Epoch: [124]
epoch 124/200, train:, losses=0.0162, top1=99.4267, 0=99.4667, 1=99.7556, 2=99.4000, 3=98.6889, 4=99.6000, 5=98.8889, 6=99.7556, 7=99.5778, 8=99.5556, 9=99.5778, val:, losses=0.3292, top1=91.9400, 0=92.4000, 1=95.4000, 2=89.8000, 3=85.6000, 4=92.8000, 5=82.8000, 6=94.8000, 7=94.4000, 8=96.6000, 9=94.8000, test:, losses=0.3351, top1=92.1600, 0=93.4000, 1=96.2000, 2=88.2000, 3=86.3000, 4=94.9000, 5=84.9000, 6=93.7000, 7=93.4000, 8=95.3000, 9=95.3000, 49.4s 1.7h/2.8h
Epoch: [125]
epoch 125/200, train:, losses=0.0153, top1=99.4600, 0=99.6444, 1=99.7333, 2=99.2889, 3=99.0444, 4=99.4000, 5=99.0444, 6=99.6889, 7=99.5778, 8=99.6667, 9=99.5111, val:, losses=0.3288, top1=92.3000, 0=94.0000, 1=96.4000, 2=90.6000, 3=82.8000, 4=94.0000, 5=85.0000, 6=94.6000, 7=94.2000, 8=97.4000, 9=94.0000, test:, losses=0.3401, top1=92.1900, 0=95.0000, 1=96.7000, 2=87.7000, 3=83.9000, 4=95.1000, 5=87.9000, 6=93.4000, 7=93.4000, 8=94.7000, 9=94.1000, 50.5s 1.8h/2.8h
Epoch: [126]
epoch 126/200, train:, losses=0.0150, top1=99.4489, 0=99.5778, 1=99.6000, 2=99.2889, 3=98.8667, 4=99.4222, 5=99.0667, 6=99.6889, 7=99.6667, 8=99.7111, 9=99.6000, val:, losses=0.3330, top1=91.9800, 0=92.2000, 1=96.6000, 2=89.0000, 3=83.8000, 4=94.2000, 5=84.2000, 6=95.8000, 7=94.4000, 8=96.8000, 9=92.8000, test:, losses=0.3427, top1=92.0800, 0=92.9000, 1=97.0000, 2=87.7000, 3=84.1000, 4=94.8000, 5=87.5000, 6=94.6000, 7=93.0000, 8=96.0000, 9=93.2000, 51.2s 1.8h/2.8h
Epoch: [127]
epoch 127/200, train:, losses=0.0158, top1=99.3978, 0=99.5333, 1=99.6000, 2=99.4667, 3=98.8000, 4=99.5111, 5=98.8000, 6=99.4222, 7=99.5111, 8=99.6889, 9=99.6444, val:, losses=0.3233, top1=92.2800, 0=93.8000, 1=96.4000, 2=88.2000, 3=82.8000, 4=95.2000, 5=85.2000, 6=95.6000, 7=95.4000, 8=95.8000, 9=94.4000, test:, losses=0.3476, top1=92.0100, 0=94.9000, 1=96.9000, 2=86.6000, 3=82.1000, 4=95.0000, 5=87.8000, 6=94.2000, 7=93.7000, 8=94.4000, 9=94.5000, 51.1s 1.8h/2.8h
Epoch: [128]
epoch 128/200, train:, losses=0.0157, top1=99.3978, 0=99.4222, 1=99.6889, 2=99.2667, 3=98.4444, 4=99.4889, 5=98.8889, 6=99.7778, 7=99.5333, 8=99.7778, 9=99.6889, val:, losses=0.3304, top1=92.2000, 0=93.0000, 1=97.0000, 2=90.2000, 3=84.6000, 4=93.2000, 5=84.0000, 6=95.2000, 7=94.6000, 8=96.2000, 9=94.0000, test:, losses=0.3419, top1=92.1100, 0=93.6000, 1=97.5000, 2=87.4000, 3=84.2000, 4=94.4000, 5=87.5000, 6=94.2000, 7=92.9000, 8=95.1000, 9=94.3000, 51.4s 1.8h/2.8h
Epoch: [129]
epoch 129/200, train:, losses=0.0139, top1=99.4978, 0=99.6444, 1=99.7111, 2=99.2444, 3=99.1333, 4=99.5778, 5=99.1333, 6=99.6667, 7=99.6000, 8=99.6889, 9=99.5778, val:, losses=0.3389, top1=91.9400, 0=91.6000, 1=95.6000, 2=89.8000, 3=83.4000, 4=94.4000, 5=82.8000, 6=95.8000, 7=94.6000, 8=96.6000, 9=94.8000, test:, losses=0.3406, top1=92.2300, 0=92.8000, 1=96.4000, 2=87.8000, 3=84.6000, 4=95.0000, 5=86.4000, 6=94.3000, 7=94.3000, 8=95.3000, 9=95.4000, 51.2s 1.8h/2.8h
Epoch: [130]
epoch 130/200, train:, losses=0.0139, top1=99.4889, 0=99.5556, 1=99.7778, 2=99.4222, 3=99.0667, 4=99.4444, 5=99.1111, 6=99.5778, 7=99.6667, 8=99.7333, 9=99.5333, val:, losses=0.3375, top1=91.9400, 0=92.0000, 1=95.6000, 2=89.2000, 3=83.2000, 4=94.0000, 5=83.0000, 6=95.2000, 7=96.0000, 8=96.0000, 9=95.2000, test:, losses=0.3451, top1=92.2200, 0=92.1000, 1=96.1000, 2=87.2000, 3=85.0000, 4=95.6000, 5=87.2000, 6=93.7000, 7=94.8000, 8=95.2000, 9=95.3000, 51.0s 1.8h/2.8h
Epoch: [131]
epoch 131/200, train:, losses=0.0147, top1=99.4733, 0=99.6889, 1=99.7333, 2=99.2667, 3=98.9778, 4=99.6444, 5=98.9556, 6=99.5778, 7=99.6222, 8=99.6667, 9=99.6000, val:, losses=0.3414, top1=91.9000, 0=93.2000, 1=96.6000, 2=89.8000, 3=82.8000, 4=93.4000, 5=83.0000, 6=95.8000, 7=94.8000, 8=96.6000, 9=93.0000, test:, losses=0.3512, top1=92.1200, 0=92.7000, 1=97.6000, 2=88.3000, 3=83.5000, 4=95.6000, 5=86.5000, 6=93.9000, 7=94.1000, 8=95.9000, 9=93.1000, 51.6s 1.8h/2.8h
Epoch: [132]
epoch 132/200, train:, losses=0.0132, top1=99.5489, 0=99.6000, 1=99.6889, 2=99.4222, 3=99.1556, 4=99.7778, 5=99.0667, 6=99.8000, 7=99.7111, 8=99.8222, 9=99.4444, val:, losses=0.3390, top1=92.0200, 0=92.2000, 1=96.4000, 2=90.4000, 3=79.4000, 4=94.2000, 5=85.4000, 6=95.6000, 7=95.6000, 8=96.8000, 9=94.2000, test:, losses=0.3503, top1=92.1700, 0=92.7000, 1=96.9000, 2=88.0000, 3=81.1000, 4=94.8000, 5=89.2000, 6=94.6000, 7=95.0000, 8=95.2000, 9=94.2000, 52.0s 1.9h/2.8h
Epoch: [133]
epoch 133/200, train:, losses=0.0128, top1=99.5156, 0=99.6889, 1=99.8889, 2=99.3111, 3=99.0222, 4=99.5556, 5=98.9333, 6=99.6444, 7=99.6889, 8=99.7333, 9=99.6889, val:, losses=0.3392, top1=92.1000, 0=93.0000, 1=95.8000, 2=90.2000, 3=84.0000, 4=94.4000, 5=82.0000, 6=95.6000, 7=94.4000, 8=96.4000, 9=95.2000, test:, losses=0.3552, top1=92.0500, 0=92.1000, 1=95.9000, 2=88.7000, 3=84.7000, 4=95.0000, 5=85.1000, 6=93.9000, 7=95.1000, 8=95.5000, 9=94.5000, 50.8s 1.9h/2.8h
Epoch: [134]
epoch 134/200, train:, losses=0.0125, top1=99.5289, 0=99.5333, 1=99.6889, 2=99.4444, 3=98.7111, 4=99.5111, 5=99.3111, 6=99.7333, 7=99.8222, 8=99.8000, 9=99.7333, val:, losses=0.3443, top1=92.2200, 0=93.4000, 1=96.6000, 2=90.6000, 3=84.8000, 4=94.2000, 5=81.0000, 6=95.0000, 7=95.4000, 8=96.8000, 9=94.4000, test:, losses=0.3548, top1=92.0500, 0=93.6000, 1=97.1000, 2=87.6000, 3=84.8000, 4=95.5000, 5=84.1000, 6=94.0000, 7=94.6000, 8=95.2000, 9=94.0000, 51.1s 1.9h/2.8h
Epoch: [135]
epoch 135/200, train:, losses=0.0126, top1=99.5156, 0=99.6444, 1=99.7556, 2=99.3778, 3=99.0889, 4=99.4667, 5=99.0889, 6=99.6444, 7=99.6889, 8=99.8000, 9=99.6000, val:, losses=0.3429, top1=92.2600, 0=93.8000, 1=96.2000, 2=90.0000, 3=80.2000, 4=94.6000, 5=85.4000, 6=95.8000, 7=95.2000, 8=96.2000, 9=95.2000, test:, losses=0.3566, top1=92.2000, 0=94.3000, 1=97.1000, 2=88.1000, 3=80.4000, 4=95.4000, 5=87.8000, 6=94.8000, 7=94.6000, 8=95.3000, 9=94.2000, 51.1s 1.9h/2.8h
Epoch: [136]
epoch 136/200, train:, losses=0.0123, top1=99.5422, 0=99.6222, 1=99.8000, 2=99.4222, 3=99.0444, 4=99.6667, 5=99.0000, 6=99.7111, 7=99.6667, 8=99.7556, 9=99.7333, val:, losses=0.3433, top1=92.2200, 0=91.4000, 1=96.6000, 2=90.0000, 3=83.4000, 4=95.0000, 5=84.2000, 6=96.0000, 7=94.2000, 8=96.4000, 9=95.0000, test:, losses=0.3509, top1=92.0900, 0=91.9000, 1=96.6000, 2=88.6000, 3=84.6000, 4=95.0000, 5=86.6000, 6=94.6000, 7=93.7000, 8=95.1000, 9=94.2000, 51.1s 1.9h/2.8h
Epoch: [137]
epoch 137/200, train:, losses=0.0117, top1=99.5978, 0=99.7778, 1=99.8000, 2=99.4000, 3=99.1556, 4=99.7333, 5=99.2222, 6=99.6000, 7=99.7556, 8=99.7778, 9=99.7556, val:, losses=0.3501, top1=92.1000, 0=92.8000, 1=95.0000, 2=90.0000, 3=81.8000, 4=94.4000, 5=83.6000, 6=95.4000, 7=95.4000, 8=96.6000, 9=96.0000, test:, losses=0.3531, top1=92.1800, 0=93.5000, 1=95.6000, 2=87.3000, 3=83.8000, 4=95.0000, 5=86.2000, 6=95.0000, 7=94.7000, 8=95.8000, 9=94.9000, 49.6s 1.9h/2.8h
Epoch: [138]
epoch 138/200, train:, losses=0.0112, top1=99.6222, 0=99.6444, 1=99.8000, 2=99.4889, 3=99.2444, 4=99.6889, 5=99.3556, 6=99.7333, 7=99.7333, 8=99.8222, 9=99.7111, val:, losses=0.3557, top1=92.1400, 0=93.6000, 1=95.2000, 2=90.2000, 3=83.2000, 4=94.0000, 5=82.6000, 6=95.6000, 7=95.6000, 8=95.6000, 9=95.8000, test:, losses=0.3612, top1=91.9500, 0=93.2000, 1=95.6000, 2=88.6000, 3=84.3000, 4=94.8000, 5=85.1000, 6=94.3000, 7=94.7000, 8=94.2000, 9=94.7000, 48.8s 1.9h/2.8h
Epoch: [139]
epoch 139/200, train:, losses=0.0116, top1=99.5778, 0=99.7111, 1=99.7333, 2=99.5333, 3=99.1333, 4=99.6222, 5=99.2222, 6=99.7333, 7=99.7556, 8=99.6667, 9=99.6667, val:, losses=0.3541, top1=92.1800, 0=93.6000, 1=96.0000, 2=90.6000, 3=81.2000, 4=93.2000, 5=85.4000, 6=95.0000, 7=94.8000, 8=96.2000, 9=95.8000, test:, losses=0.3579, top1=92.0300, 0=92.8000, 1=96.3000, 2=88.1000, 3=82.6000, 4=94.5000, 5=87.1000, 6=94.3000, 7=94.6000, 8=95.3000, 9=94.7000, 50.8s 2.0h/2.8h
Epoch: [140]
epoch 140/200, train:, losses=0.0107, top1=99.6400, 0=99.5778, 1=99.8222, 2=99.4444, 3=99.2000, 4=99.6889, 5=99.3333, 6=99.8444, 7=99.7556, 8=99.8444, 9=99.8889, val:, losses=0.3509, top1=92.2600, 0=93.0000, 1=96.2000, 2=89.0000, 3=81.2000, 4=94.2000, 5=86.6000, 6=95.6000, 7=94.4000, 8=96.6000, 9=95.8000, test:, losses=0.3701, top1=91.9800, 0=92.1000, 1=96.5000, 2=87.3000, 3=82.6000, 4=94.4000, 5=87.8000, 6=94.5000, 7=93.8000, 8=96.1000, 9=94.7000, 51.0s 2.0h/2.8h
Epoch: [141]
epoch 141/200, train:, losses=0.0104, top1=99.6356, 0=99.7333, 1=99.6889, 2=99.5333, 3=99.2889, 4=99.7333, 5=99.3556, 6=99.8444, 7=99.6889, 8=99.7333, 9=99.7556, val:, losses=0.3508, top1=92.1600, 0=93.4000, 1=96.4000, 2=89.6000, 3=83.0000, 4=94.4000, 5=84.0000, 6=94.8000, 7=94.4000, 8=96.6000, 9=95.0000, test:, losses=0.3654, top1=92.1600, 0=93.1000, 1=96.1000, 2=88.3000, 3=84.1000, 4=94.7000, 5=86.2000, 6=94.6000, 7=94.6000, 8=95.4000, 9=94.5000, 50.6s 2.0h/2.8h
Epoch: [142]
epoch 142/200, train:, losses=0.0106, top1=99.6311, 0=99.7333, 1=99.8667, 2=99.4667, 3=99.4444, 4=99.7778, 5=99.2889, 6=99.6889, 7=99.6889, 8=99.7778, 9=99.5778, val:, losses=0.3626, top1=91.8200, 0=93.4000, 1=96.0000, 2=90.2000, 3=81.6000, 4=92.8000, 5=84.0000, 6=95.4000, 7=94.0000, 8=96.4000, 9=94.4000, test:, losses=0.3686, top1=92.0500, 0=93.0000, 1=96.6000, 2=88.4000, 3=83.4000, 4=94.2000, 5=87.4000, 6=94.2000, 7=93.8000, 8=95.3000, 9=94.2000, 49.2s 2.0h/2.8h
Epoch: [143]
epoch 143/200, train:, losses=0.0115, top1=99.5867, 0=99.7111, 1=99.8444, 2=99.5111, 3=99.0444, 4=99.6667, 5=99.1778, 6=99.6222, 7=99.7333, 8=99.8000, 9=99.7556, val:, losses=0.3640, top1=92.1400, 0=94.4000, 1=95.4000, 2=89.4000, 3=81.2000, 4=95.2000, 5=85.4000, 6=95.0000, 7=94.2000, 8=96.2000, 9=95.0000, test:, losses=0.3790, top1=91.9400, 0=94.6000, 1=96.0000, 2=87.2000, 3=81.4000, 4=95.5000, 5=88.6000, 6=93.5000, 7=93.9000, 8=94.4000, 9=94.3000, 49.8s 2.0h/2.8h
Epoch: [144]
epoch 144/200, train:, losses=0.0105, top1=99.6822, 0=99.8000, 1=99.8222, 2=99.6222, 3=99.2889, 4=99.6889, 5=99.3111, 6=99.8667, 7=99.7111, 8=99.9111, 9=99.8000, val:, losses=0.3531, top1=92.3000, 0=92.8000, 1=96.2000, 2=89.8000, 3=82.6000, 4=94.4000, 5=85.2000, 6=95.0000, 7=94.6000, 8=96.2000, 9=96.2000, test:, losses=0.3666, top1=92.0200, 0=93.5000, 1=96.5000, 2=86.8000, 3=83.9000, 4=94.4000, 5=87.3000, 6=94.3000, 7=93.9000, 8=94.9000, 9=94.7000, 49.3s 2.0h/2.8h
Epoch: [145]
epoch 145/200, train:, losses=0.0107, top1=99.6044, 0=99.5778, 1=99.7556, 2=99.5111, 3=99.0444, 4=99.7111, 5=99.4000, 6=99.7556, 7=99.8000, 8=99.8667, 9=99.6222, val:, losses=0.3635, top1=92.2800, 0=93.0000, 1=96.0000, 2=91.4000, 3=82.0000, 4=93.8000, 5=86.0000, 6=95.2000, 7=94.4000, 8=96.4000, 9=94.6000, test:, losses=0.3703, top1=92.1600, 0=92.8000, 1=96.6000, 2=88.2000, 3=84.0000, 4=94.6000, 5=87.9000, 6=94.0000, 7=94.0000, 8=95.3000, 9=94.2000, 50.6s 2.0h/2.8h
Epoch: [146]
epoch 146/200, train:, losses=0.0099, top1=99.6711, 0=99.7111, 1=99.8444, 2=99.6889, 3=99.2667, 4=99.8000, 5=99.3556, 6=99.8444, 7=99.6889, 8=99.8222, 9=99.6889, val:, losses=0.3639, top1=92.0200, 0=92.0000, 1=95.4000, 2=89.6000, 3=83.4000, 4=92.8000, 5=85.4000, 6=94.8000, 7=94.4000, 8=96.6000, 9=95.8000, test:, losses=0.3669, top1=92.3100, 0=93.0000, 1=96.6000, 2=87.6000, 3=85.1000, 4=94.2000, 5=87.6000, 6=94.4000, 7=94.1000, 8=95.8000, 9=94.7000, 49.5s 2.0h/2.8h
Epoch: [147]
epoch 147/200, train:, losses=0.0099, top1=99.6689, 0=99.5778, 1=99.9556, 2=99.5333, 3=99.4000, 4=99.7556, 5=99.4222, 6=99.8222, 7=99.7333, 8=99.7778, 9=99.7111, val:, losses=0.3528, top1=91.8600, 0=92.6000, 1=95.4000, 2=87.6000, 3=81.6000, 4=93.2000, 5=85.4000, 6=95.6000, 7=95.4000, 8=96.8000, 9=95.0000, test:, losses=0.3692, top1=92.2600, 0=93.3000, 1=96.9000, 2=87.0000, 3=83.7000, 4=94.9000, 5=88.3000, 6=94.2000, 7=94.6000, 8=95.1000, 9=94.6000, 50.3s 2.1h/2.8h
Epoch: [148]
epoch 148/200, train:, losses=0.0095, top1=99.7044, 0=99.8222, 1=99.8667, 2=99.6667, 3=99.3111, 4=99.8000, 5=99.3778, 6=99.8000, 7=99.8444, 8=99.8000, 9=99.7556, val:, losses=0.3695, top1=92.1000, 0=93.6000, 1=96.2000, 2=89.4000, 3=80.8000, 4=94.2000, 5=85.8000, 6=95.2000, 7=94.4000, 8=97.0000, 9=94.4000, test:, losses=0.3728, top1=92.1600, 0=93.9000, 1=97.4000, 2=87.6000, 3=82.7000, 4=94.2000, 5=88.3000, 6=94.1000, 7=94.0000, 8=95.7000, 9=93.7000, 51.7s 2.1h/2.8h
Epoch: [149]
epoch 149/200, train:, losses=0.0090, top1=99.6911, 0=99.8444, 1=99.8444, 2=99.5333, 3=99.2444, 4=99.7333, 5=99.4667, 6=99.8000, 7=99.7556, 8=99.7778, 9=99.9111, val:, losses=0.3648, top1=91.9400, 0=92.2000, 1=96.6000, 2=89.2000, 3=79.0000, 4=94.6000, 5=86.0000, 6=95.4000, 7=95.0000, 8=96.4000, 9=95.0000, test:, losses=0.3722, top1=92.0700, 0=93.3000, 1=96.9000, 2=88.0000, 3=80.1000, 4=94.6000, 5=89.0000, 6=94.3000, 7=95.0000, 8=95.6000, 9=93.9000, 49.8s 2.1h/2.8h
Epoch: [150]
epoch 150/200, train:, losses=0.0082, top1=99.7667, 0=99.8000, 1=99.9556, 2=99.5778, 3=99.4667, 4=99.7556, 5=99.6000, 6=99.8667, 7=99.8667, 8=99.9778, 9=99.8000, val:, losses=0.3569, top1=91.8800, 0=92.4000, 1=95.8000, 2=89.4000, 3=80.8000, 4=94.6000, 5=84.4000, 6=95.2000, 7=94.8000, 8=96.0000, 9=95.4000, test:, losses=0.3621, top1=92.2000, 0=93.1000, 1=96.5000, 2=88.4000, 3=82.2000, 4=95.0000, 5=87.7000, 6=94.3000, 7=94.6000, 8=95.8000, 9=94.4000, 50.8s 2.1h/2.8h
Epoch: [151]
epoch 151/200, train:, losses=0.0079, top1=99.7556, 0=99.7111, 1=99.9111, 2=99.6444, 3=99.5333, 4=99.7556, 5=99.7556, 6=99.8000, 7=99.7111, 8=99.9111, 9=99.8222, val:, losses=0.3565, top1=92.0600, 0=92.2000, 1=96.6000, 2=89.6000, 3=81.4000, 4=94.2000, 5=85.2000, 6=95.8000, 7=94.6000, 8=95.8000, 9=95.2000, test:, losses=0.3615, top1=92.2500, 0=93.2000, 1=97.2000, 2=88.1000, 3=82.8000, 4=94.0000, 5=88.5000, 6=94.5000, 7=94.5000, 8=95.6000, 9=94.1000, 51.5s 2.1h/2.8h
Epoch: [152]
epoch 152/200, train:, losses=0.0077, top1=99.7467, 0=99.8222, 1=99.9111, 2=99.6667, 3=99.5333, 4=99.7778, 5=99.4444, 6=99.8444, 7=99.8222, 8=99.9333, 9=99.7111, val:, losses=0.3564, top1=92.0400, 0=92.6000, 1=96.6000, 2=89.2000, 3=82.4000, 4=93.6000, 5=84.2000, 6=95.8000, 7=95.0000, 8=96.0000, 9=95.0000, test:, losses=0.3637, top1=92.2000, 0=93.4000, 1=97.8000, 2=88.3000, 3=82.6000, 4=93.8000, 5=87.9000, 6=94.5000, 7=94.7000, 8=94.9000, 9=94.1000, 51.1s 2.1h/2.8h
Epoch: [153]
epoch 153/200, train:, losses=0.0070, top1=99.7911, 0=99.6889, 1=99.8889, 2=99.8000, 3=99.6667, 4=99.8889, 5=99.5333, 6=99.8444, 7=99.8444, 8=99.9556, 9=99.8000, val:, losses=0.3577, top1=92.0000, 0=92.2000, 1=96.4000, 2=89.2000, 3=82.2000, 4=93.6000, 5=84.6000, 6=96.0000, 7=94.8000, 8=95.8000, 9=95.2000, test:, losses=0.3636, top1=92.2500, 0=93.3000, 1=97.1000, 2=87.5000, 3=82.9000, 4=93.8000, 5=88.9000, 6=95.1000, 7=94.5000, 8=95.4000, 9=94.0000, 50.5s 2.1h/2.8h
Epoch: [154]
epoch 154/200, train:, losses=0.0073, top1=99.7822, 0=99.8222, 1=99.9556, 2=99.7556, 3=99.6444, 4=99.7111, 5=99.6000, 6=99.8444, 7=99.8667, 8=99.8444, 9=99.7778, val:, losses=0.3519, top1=92.1000, 0=94.0000, 1=96.6000, 2=89.2000, 3=81.4000, 4=94.0000, 5=84.4000, 6=95.8000, 7=94.8000, 8=96.0000, 9=94.8000, test:, losses=0.3627, top1=92.2700, 0=94.0000, 1=97.6000, 2=87.7000, 3=82.4000, 4=94.4000, 5=88.5000, 6=94.6000, 7=94.5000, 8=95.0000, 9=94.0000, 50.8s 2.2h/2.8h
Epoch: [155]
epoch 155/200, train:, losses=0.0067, top1=99.8000, 0=99.8667, 1=99.8444, 2=99.8000, 3=99.6667, 4=99.8889, 5=99.6444, 6=99.8667, 7=99.7333, 8=99.8667, 9=99.8222, val:, losses=0.3584, top1=92.0800, 0=92.4000, 1=96.2000, 2=88.8000, 3=82.4000, 4=94.0000, 5=85.2000, 6=95.6000, 7=94.8000, 8=96.0000, 9=95.4000, test:, losses=0.3650, top1=92.1700, 0=93.2000, 1=96.8000, 2=87.3000, 3=82.8000, 4=94.2000, 5=88.3000, 6=94.1000, 7=94.7000, 8=95.5000, 9=94.8000, 51.6s 2.2h/2.8h
Epoch: [156]
epoch 156/200, train:, losses=0.0074, top1=99.7733, 0=99.8222, 1=99.8889, 2=99.7556, 3=99.4889, 4=99.7333, 5=99.5778, 6=99.9111, 7=99.8000, 8=99.9111, 9=99.8444, val:, losses=0.3554, top1=92.0800, 0=92.8000, 1=96.4000, 2=89.0000, 3=82.2000, 4=94.0000, 5=85.0000, 6=95.6000, 7=94.8000, 8=95.8000, 9=95.2000, test:, losses=0.3594, top1=92.2900, 0=93.0000, 1=96.8000, 2=87.6000, 3=83.9000, 4=94.1000, 5=87.6000, 6=94.8000, 7=94.5000, 8=95.9000, 9=94.7000, 51.7s 2.2h/2.8h
Epoch: [157]
epoch 157/200, train:, losses=0.0072, top1=99.7867, 0=99.8000, 1=99.8444, 2=99.6444, 3=99.6444, 4=99.8889, 5=99.6667, 6=99.8889, 7=99.8444, 8=99.8889, 9=99.7556, val:, losses=0.3588, top1=92.0200, 0=93.2000, 1=96.0000, 2=89.0000, 3=81.8000, 4=94.2000, 5=85.0000, 6=95.6000, 7=94.6000, 8=95.8000, 9=95.0000, test:, losses=0.3635, top1=92.2900, 0=93.6000, 1=97.2000, 2=87.6000, 3=83.4000, 4=94.1000, 5=88.2000, 6=94.7000, 7=94.3000, 8=95.3000, 9=94.5000, 51.1s 2.2h/2.8h
Epoch: [158]
epoch 158/200, train:, losses=0.0064, top1=99.8556, 0=99.8444, 1=99.9333, 2=99.8889, 3=99.6000, 4=99.9333, 5=99.8444, 6=99.8667, 7=99.9333, 8=99.8667, 9=99.8444, val:, losses=0.3575, top1=92.1400, 0=93.0000, 1=96.2000, 2=89.2000, 3=82.8000, 4=94.8000, 5=84.0000, 6=95.6000, 7=94.6000, 8=95.8000, 9=95.4000, test:, losses=0.3623, top1=92.2400, 0=93.4000, 1=96.6000, 2=88.0000, 3=84.3000, 4=94.5000, 5=86.5000, 6=94.7000, 7=94.3000, 8=95.4000, 9=94.7000, 51.4s 2.2h/2.8h
Epoch: [159]
epoch 159/200, train:, losses=0.0070, top1=99.8044, 0=99.8000, 1=99.9111, 2=99.7556, 3=99.6000, 4=99.8444, 5=99.7111, 6=99.9333, 7=99.8222, 8=99.8222, 9=99.8444, val:, losses=0.3591, top1=92.0600, 0=92.6000, 1=96.6000, 2=90.0000, 3=81.4000, 4=94.4000, 5=84.6000, 6=95.2000, 7=94.8000, 8=95.8000, 9=95.2000, test:, losses=0.3625, top1=92.3000, 0=93.2000, 1=97.3000, 2=88.5000, 3=82.7000, 4=94.4000, 5=88.5000, 6=93.9000, 7=94.6000, 8=95.5000, 9=94.4000, 51.2s 2.2h/2.8h
Epoch: [160]
epoch 160/200, train:, losses=0.0067, top1=99.7956, 0=99.9111, 1=99.8444, 2=99.6667, 3=99.6000, 4=99.8444, 5=99.6000, 6=99.8444, 7=99.9111, 8=99.8444, 9=99.8889, val:, losses=0.3550, top1=92.1400, 0=92.4000, 1=96.6000, 2=90.6000, 3=81.6000, 4=94.6000, 5=84.8000, 6=95.6000, 7=94.4000, 8=95.8000, 9=95.0000, test:, losses=0.3585, top1=92.3100, 0=93.2000, 1=97.4000, 2=88.4000, 3=83.3000, 4=94.5000, 5=88.1000, 6=94.2000, 7=94.3000, 8=95.2000, 9=94.5000, 50.4s 2.2h/2.8h
Epoch: [161]
epoch 161/200, train:, losses=0.0067, top1=99.7956, 0=99.8444, 1=99.9111, 2=99.7778, 3=99.6667, 4=99.6889, 5=99.6222, 6=99.8444, 7=99.8444, 8=99.8667, 9=99.8889, val:, losses=0.3586, top1=92.1200, 0=92.6000, 1=96.6000, 2=89.8000, 3=83.0000, 4=93.8000, 5=84.4000, 6=95.4000, 7=94.4000, 8=95.8000, 9=95.4000, test:, losses=0.3624, top1=92.2700, 0=93.0000, 1=97.0000, 2=88.2000, 3=85.0000, 4=93.8000, 5=87.5000, 6=94.0000, 7=94.4000, 8=95.4000, 9=94.4000, 49.9s 2.3h/2.8h
Epoch: [162]
epoch 162/200, train:, losses=0.0061, top1=99.8289, 0=99.9111, 1=99.8889, 2=99.7556, 3=99.5556, 4=99.9111, 5=99.7333, 6=99.9333, 7=99.8667, 8=99.9333, 9=99.8000, val:, losses=0.3586, top1=92.2400, 0=92.8000, 1=96.6000, 2=90.6000, 3=82.6000, 4=94.4000, 5=84.4000, 6=95.6000, 7=94.6000, 8=95.8000, 9=95.0000, test:, losses=0.3616, top1=92.3000, 0=93.2000, 1=97.1000, 2=88.8000, 3=84.5000, 4=94.4000, 5=87.0000, 6=94.1000, 7=94.6000, 8=95.0000, 9=94.3000, 51.3s 2.3h/2.8h
Epoch: [163]
epoch 163/200, train:, losses=0.0062, top1=99.8378, 0=99.8667, 1=99.9556, 2=99.7556, 3=99.7556, 4=99.8889, 5=99.6000, 6=99.8889, 7=99.8000, 8=99.9333, 9=99.9333, val:, losses=0.3604, top1=92.2000, 0=92.8000, 1=96.0000, 2=90.8000, 3=81.4000, 4=94.8000, 5=84.8000, 6=95.4000, 7=94.6000, 8=96.6000, 9=94.8000, test:, losses=0.3624, top1=92.2600, 0=93.3000, 1=96.9000, 2=89.1000, 3=82.9000, 4=94.8000, 5=87.0000, 6=94.0000, 7=94.3000, 8=96.1000, 9=94.2000, 49.3s 2.3h/2.8h
Epoch: [164]
epoch 164/200, train:, losses=0.0062, top1=99.8200, 0=99.9111, 1=99.8889, 2=99.7778, 3=99.6889, 4=99.8444, 5=99.6889, 6=99.8889, 7=99.8000, 8=99.8667, 9=99.8444, val:, losses=0.3599, top1=92.1600, 0=92.8000, 1=96.6000, 2=90.2000, 3=81.8000, 4=94.6000, 5=84.2000, 6=95.6000, 7=94.8000, 8=96.2000, 9=94.8000, test:, losses=0.3651, top1=92.3600, 0=93.2000, 1=97.6000, 2=88.3000, 3=83.4000, 4=94.8000, 5=87.2000, 6=94.4000, 7=94.5000, 8=96.0000, 9=94.2000, 50.9s 2.3h/2.8h
Epoch: [165]
epoch 165/200, train:, losses=0.0063, top1=99.8378, 0=99.8667, 1=99.9778, 2=99.8222, 3=99.7333, 4=99.8889, 5=99.7556, 6=99.9111, 7=99.7111, 8=99.8444, 9=99.8667, val:, losses=0.3587, top1=92.2800, 0=93.4000, 1=96.6000, 2=89.6000, 3=82.2000, 4=94.2000, 5=85.0000, 6=95.6000, 7=94.8000, 8=96.8000, 9=94.6000, test:, losses=0.3645, top1=92.3400, 0=93.2000, 1=97.4000, 2=88.6000, 3=83.1000, 4=94.6000, 5=88.1000, 6=94.4000, 7=94.4000, 8=96.0000, 9=93.6000, 50.1s 2.3h/2.8h
Epoch: [166]
epoch 166/200, train:, losses=0.0061, top1=99.8533, 0=99.9333, 1=99.9556, 2=99.7556, 3=99.8000, 4=99.8000, 5=99.7556, 6=99.8889, 7=99.9333, 8=99.8889, 9=99.8222, val:, losses=0.3562, top1=92.2400, 0=92.8000, 1=96.6000, 2=90.6000, 3=82.0000, 4=94.4000, 5=85.0000, 6=95.6000, 7=94.6000, 8=96.0000, 9=94.8000, test:, losses=0.3627, top1=92.2700, 0=93.1000, 1=97.4000, 2=88.5000, 3=83.4000, 4=94.4000, 5=87.2000, 6=94.5000, 7=94.4000, 8=95.3000, 9=94.5000, 49.4s 2.3h/2.8h
Epoch: [167]
epoch 167/200, train:, losses=0.0061, top1=99.8578, 0=99.8667, 1=99.9333, 2=99.8444, 3=99.7778, 4=99.8889, 5=99.7111, 6=99.8222, 7=99.8667, 8=99.9333, 9=99.9333, val:, losses=0.3575, top1=92.2400, 0=93.0000, 1=96.6000, 2=88.8000, 3=83.2000, 4=94.8000, 5=84.4000, 6=95.8000, 7=94.8000, 8=96.0000, 9=95.0000, test:, losses=0.3629, top1=92.4000, 0=93.0000, 1=97.3000, 2=87.4000, 3=84.9000, 4=94.8000, 5=87.3000, 6=94.6000, 7=94.4000, 8=96.0000, 9=94.3000, 48.9s 2.3h/2.8h
Epoch: [168]
epoch 168/200, train:, losses=0.0060, top1=99.8311, 0=99.8444, 1=99.8667, 2=99.8000, 3=99.7778, 4=99.9111, 5=99.7111, 6=99.9333, 7=99.9111, 8=99.8889, 9=99.6667, val:, losses=0.3606, top1=92.1800, 0=93.4000, 1=96.4000, 2=89.6000, 3=82.2000, 4=94.6000, 5=84.6000, 6=95.6000, 7=94.8000, 8=96.0000, 9=94.6000, test:, losses=0.3662, top1=92.2100, 0=93.6000, 1=97.1000, 2=88.2000, 3=83.3000, 4=94.8000, 5=87.4000, 6=94.5000, 7=94.5000, 8=95.2000, 9=93.5000, 50.1s 2.4h/2.8h
Epoch: [169]
epoch 169/200, train:, losses=0.0063, top1=99.8378, 0=99.8222, 1=99.9556, 2=99.7778, 3=99.8444, 4=99.8444, 5=99.7556, 6=99.8667, 7=99.8667, 8=99.8667, 9=99.7778, val:, losses=0.3592, top1=92.3200, 0=93.4000, 1=96.6000, 2=90.2000, 3=83.2000, 4=94.0000, 5=85.0000, 6=95.6000, 7=94.4000, 8=96.2000, 9=94.6000, test:, losses=0.3629, top1=92.2500, 0=93.1000, 1=97.4000, 2=88.2000, 3=84.8000, 4=94.1000, 5=87.5000, 6=94.1000, 7=94.2000, 8=95.5000, 9=93.6000, 37.7s 2.4h/2.8h
Epoch: [170]
epoch 170/200, train:, losses=0.0065, top1=99.8178, 0=99.9111, 1=99.8444, 2=99.8000, 3=99.6000, 4=99.8000, 5=99.7111, 6=99.9111, 7=99.8889, 8=99.9111, 9=99.8000, val:, losses=0.3635, top1=92.2200, 0=92.6000, 1=96.6000, 2=89.2000, 3=83.0000, 4=94.6000, 5=84.8000, 6=95.4000, 7=94.8000, 8=96.0000, 9=95.2000, test:, losses=0.3677, top1=92.2700, 0=93.2000, 1=97.1000, 2=87.8000, 3=83.2000, 4=95.2000, 5=87.4000, 6=94.1000, 7=94.8000, 8=95.4000, 9=94.5000, 37.9s 2.4h/2.8h
Epoch: [171]
epoch 171/200, train:, losses=0.0062, top1=99.8622, 0=99.8889, 1=99.9556, 2=99.8000, 3=99.8222, 4=99.7556, 5=99.7556, 6=99.9111, 7=99.9333, 8=99.9556, 9=99.8444, val:, losses=0.3597, top1=92.2400, 0=92.6000, 1=96.6000, 2=89.6000, 3=83.2000, 4=94.2000, 5=84.6000, 6=95.6000, 7=94.8000, 8=96.0000, 9=95.2000, test:, losses=0.3625, top1=92.2900, 0=92.9000, 1=97.1000, 2=88.3000, 3=84.3000, 4=94.2000, 5=87.4000, 6=94.5000, 7=94.4000, 8=95.6000, 9=94.2000, 37.1s 2.4h/2.8h
Epoch: [172]
epoch 172/200, train:, losses=0.0064, top1=99.8222, 0=99.7556, 1=99.8889, 2=99.8000, 3=99.8000, 4=99.8222, 5=99.7556, 6=99.8444, 7=99.8000, 8=99.8444, 9=99.9111, val:, losses=0.3584, top1=92.2000, 0=92.8000, 1=96.4000, 2=90.2000, 3=82.2000, 4=93.8000, 5=84.8000, 6=95.6000, 7=95.0000, 8=96.0000, 9=95.2000, test:, losses=0.3643, top1=92.3200, 0=93.3000, 1=97.2000, 2=88.3000, 3=83.7000, 4=94.6000, 5=87.3000, 6=94.3000, 7=94.7000, 8=95.1000, 9=94.7000, 36.1s 2.4h/2.8h
Epoch: [173]
epoch 173/200, train:, losses=0.0061, top1=99.8378, 0=99.8000, 1=99.9333, 2=99.8667, 3=99.7778, 4=99.8444, 5=99.7556, 6=99.8444, 7=99.8000, 8=99.8889, 9=99.8667, val:, losses=0.3618, top1=92.2800, 0=92.8000, 1=96.4000, 2=90.4000, 3=81.2000, 4=94.8000, 5=85.4000, 6=95.6000, 7=95.0000, 8=96.2000, 9=95.0000, test:, losses=0.3649, top1=92.2400, 0=93.3000, 1=96.9000, 2=88.0000, 3=82.4000, 4=95.0000, 5=87.2000, 6=94.7000, 7=94.8000, 8=95.5000, 9=94.6000, 34.6s 2.4h/2.8h
Epoch: [174]
epoch 174/200, train:, losses=0.0061, top1=99.8511, 0=99.9556, 1=99.9333, 2=99.7778, 3=99.6444, 4=99.9556, 5=99.6667, 6=99.8667, 7=99.9333, 8=99.9333, 9=99.8444, val:, losses=0.3615, top1=92.1200, 0=92.6000, 1=96.6000, 2=90.0000, 3=83.4000, 4=94.8000, 5=84.4000, 6=95.2000, 7=93.6000, 8=96.0000, 9=94.6000, test:, losses=0.3662, top1=92.3100, 0=92.9000, 1=97.5000, 2=87.9000, 3=85.0000, 4=95.0000, 5=86.8000, 6=94.2000, 7=94.0000, 8=95.6000, 9=94.2000, 36.4s 2.4h/2.8h
Epoch: [175]
epoch 175/200, train:, losses=0.0059, top1=99.8267, 0=99.8889, 1=99.8667, 2=99.6889, 3=99.7778, 4=99.8444, 5=99.7111, 6=99.8889, 7=99.8667, 8=99.9556, 9=99.7778, val:, losses=0.3600, top1=92.1800, 0=92.4000, 1=96.6000, 2=90.0000, 3=82.4000, 4=94.2000, 5=85.0000, 6=95.6000, 7=94.6000, 8=95.8000, 9=95.2000, test:, losses=0.3664, top1=92.3100, 0=93.0000, 1=97.0000, 2=88.1000, 3=84.2000, 4=94.6000, 5=87.5000, 6=94.7000, 7=94.4000, 8=95.2000, 9=94.4000, 36.5s 2.4h/2.8h
Epoch: [176]
epoch 176/200, train:, losses=0.0059, top1=99.8356, 0=99.8889, 1=99.9556, 2=99.7778, 3=99.7556, 4=99.8444, 5=99.7111, 6=99.8444, 7=99.7333, 8=99.9333, 9=99.9111, val:, losses=0.3615, top1=92.2000, 0=93.6000, 1=96.6000, 2=90.4000, 3=82.6000, 4=94.2000, 5=84.2000, 6=95.0000, 7=95.0000, 8=95.4000, 9=95.0000, test:, losses=0.3679, top1=92.3200, 0=93.7000, 1=97.1000, 2=89.0000, 3=84.3000, 4=94.7000, 5=87.0000, 6=93.7000, 7=94.6000, 8=94.7000, 9=94.4000, 36.7s 2.4h/2.8h
Epoch: [177]
epoch 177/200, train:, losses=0.0058, top1=99.8378, 0=99.8444, 1=99.8222, 2=99.8222, 3=99.7778, 4=99.8889, 5=99.7333, 6=99.8444, 7=99.8667, 8=99.9333, 9=99.8444, val:, losses=0.3582, top1=92.2200, 0=93.0000, 1=96.6000, 2=90.4000, 3=82.0000, 4=94.0000, 5=84.8000, 6=95.6000, 7=95.0000, 8=95.8000, 9=95.0000, test:, losses=0.3649, top1=92.3600, 0=93.2000, 1=97.3000, 2=89.0000, 3=83.3000, 4=94.5000, 5=87.7000, 6=94.6000, 7=94.5000, 8=95.1000, 9=94.4000, 37.2s 2.5h/2.8h
Epoch: [178]
epoch 178/200, train:, losses=0.0063, top1=99.8422, 0=99.8222, 1=99.9333, 2=99.8000, 3=99.5333, 4=99.8222, 5=99.7778, 6=99.9556, 7=99.9333, 8=99.9111, 9=99.9333, val:, losses=0.3604, top1=92.1600, 0=92.4000, 1=96.6000, 2=89.8000, 3=82.6000, 4=94.8000, 5=84.2000, 6=95.6000, 7=95.0000, 8=95.8000, 9=94.8000, test:, losses=0.3633, top1=92.3500, 0=92.4000, 1=97.3000, 2=87.9000, 3=84.3000, 4=95.0000, 5=87.0000, 6=94.6000, 7=94.7000, 8=95.9000, 9=94.4000, 36.4s 2.5h/2.8h
Epoch: [179]
epoch 179/200, train:, losses=0.0058, top1=99.8244, 0=99.8444, 1=99.9111, 2=99.8000, 3=99.6889, 4=99.8222, 5=99.6667, 6=99.9111, 7=99.8222, 8=99.8667, 9=99.9111, val:, losses=0.3624, top1=92.2200, 0=93.6000, 1=96.6000, 2=89.8000, 3=82.2000, 4=95.0000, 5=83.6000, 6=95.4000, 7=95.0000, 8=96.4000, 9=94.6000, test:, losses=0.3684, top1=92.3300, 0=93.6000, 1=97.3000, 2=88.4000, 3=83.2000, 4=95.1000, 5=87.0000, 6=94.3000, 7=94.6000, 8=95.5000, 9=94.3000, 28.7s 2.5h/2.8h
Epoch: [180]
epoch 180/200, train:, losses=0.0059, top1=99.8578, 0=99.8667, 1=99.9111, 2=99.8444, 3=99.6222, 4=99.9556, 5=99.7778, 6=99.8889, 7=99.9111, 8=99.8889, 9=99.9111, val:, losses=0.3638, top1=92.2200, 0=92.8000, 1=96.6000, 2=90.4000, 3=82.2000, 4=94.4000, 5=84.8000, 6=96.0000, 7=95.0000, 8=96.0000, 9=94.0000, test:, losses=0.3678, top1=92.3800, 0=92.8000, 1=97.6000, 2=88.8000, 3=83.6000, 4=94.5000, 5=87.9000, 6=94.7000, 7=94.5000, 8=95.5000, 9=93.9000, 28.0s 2.5h/2.8h
Epoch: [181]
epoch 181/200, train:, losses=0.0056, top1=99.8689, 0=99.9111, 1=99.9556, 2=99.8667, 3=99.7556, 4=99.8667, 5=99.8444, 6=99.8667, 7=99.8444, 8=99.9111, 9=99.8667, val:, losses=0.3632, top1=92.2000, 0=93.0000, 1=96.2000, 2=90.6000, 3=81.8000, 4=94.8000, 5=84.2000, 6=95.6000, 7=95.0000, 8=95.4000, 9=95.4000, test:, losses=0.3676, top1=92.3400, 0=93.1000, 1=97.2000, 2=88.8000, 3=83.6000, 4=94.9000, 5=87.2000, 6=94.3000, 7=94.7000, 8=95.0000, 9=94.6000, 28.0s 2.5h/2.7h
Epoch: [182]
epoch 182/200, train:, losses=0.0057, top1=99.8533, 0=99.9333, 1=99.9111, 2=99.6889, 3=99.8000, 4=99.8889, 5=99.8444, 6=99.8889, 7=99.8667, 8=99.8889, 9=99.8222, val:, losses=0.3587, top1=92.3800, 0=93.2000, 1=96.8000, 2=90.2000, 3=82.4000, 4=94.2000, 5=86.0000, 6=95.6000, 7=95.0000, 8=95.4000, 9=95.0000, test:, losses=0.3674, top1=92.2800, 0=93.6000, 1=97.5000, 2=88.4000, 3=82.7000, 4=94.2000, 5=88.1000, 6=94.2000, 7=95.0000, 8=94.8000, 9=94.3000, 28.4s 2.5h/2.7h
Epoch: [183]
epoch 183/200, train:, losses=0.0056, top1=99.8511, 0=99.8222, 1=99.9333, 2=99.8667, 3=99.7111, 4=99.7778, 5=99.8000, 6=99.9333, 7=99.8889, 8=99.8889, 9=99.8889, val:, losses=0.3614, top1=92.3000, 0=93.6000, 1=96.8000, 2=90.2000, 3=81.8000, 4=94.4000, 5=84.6000, 6=96.0000, 7=95.0000, 8=96.0000, 9=94.6000, test:, losses=0.3678, top1=92.4000, 0=93.6000, 1=97.7000, 2=88.4000, 3=83.2000, 4=94.4000, 5=87.5000, 6=94.7000, 7=94.7000, 8=95.4000, 9=94.4000, 29.2s 2.5h/2.7h
Epoch: [184]
epoch 184/200, train:, losses=0.0057, top1=99.8689, 0=99.8222, 1=99.9333, 2=99.8222, 3=99.6667, 4=99.9778, 5=99.7556, 6=99.9778, 7=99.9333, 8=99.9556, 9=99.8444, val:, losses=0.3628, top1=92.2600, 0=92.6000, 1=96.4000, 2=90.2000, 3=82.2000, 4=94.6000, 5=85.0000, 6=95.6000, 7=94.6000, 8=95.6000, 9=95.8000, test:, losses=0.3678, top1=92.3300, 0=93.2000, 1=96.9000, 2=88.8000, 3=83.2000, 4=94.6000, 5=87.8000, 6=94.4000, 7=94.5000, 8=95.0000, 9=94.9000, 28.6s 2.5h/2.7h
Epoch: [185]
epoch 185/200, train:, losses=0.0056, top1=99.8422, 0=99.8444, 1=99.9333, 2=99.8444, 3=99.7333, 4=99.8000, 5=99.7111, 6=99.8889, 7=99.8667, 8=99.8889, 9=99.9111, val:, losses=0.3642, top1=92.2000, 0=92.6000, 1=96.6000, 2=90.6000, 3=81.6000, 4=94.6000, 5=85.0000, 6=95.6000, 7=94.8000, 8=96.2000, 9=94.4000, test:, losses=0.3689, top1=92.4100, 0=93.0000, 1=97.4000, 2=89.3000, 3=83.3000, 4=95.2000, 5=86.9000, 6=94.8000, 7=94.5000, 8=95.5000, 9=94.2000, 28.2s 2.5h/2.7h
Epoch: [186]
epoch 186/200, train:, losses=0.0055, top1=99.8667, 0=99.8667, 1=99.9556, 2=99.9333, 3=99.8222, 4=99.8222, 5=99.7111, 6=99.8667, 7=99.9333, 8=99.9111, 9=99.8444, val:, losses=0.3645, top1=92.1800, 0=93.4000, 1=96.6000, 2=90.4000, 3=81.6000, 4=94.4000, 5=86.0000, 6=95.0000, 7=94.4000, 8=95.8000, 9=94.2000, test:, losses=0.3711, top1=92.3400, 0=93.4000, 1=97.1000, 2=88.9000, 3=82.5000, 4=94.8000, 5=88.6000, 6=94.0000, 7=94.5000, 8=95.4000, 9=94.2000, 27.8s 2.5h/2.7h
Epoch: [187]
epoch 187/200, train:, losses=0.0055, top1=99.8622, 0=99.8222, 1=99.8667, 2=99.9556, 3=99.7556, 4=99.8889, 5=99.7556, 6=99.8889, 7=99.9333, 8=99.9111, 9=99.8444, val:, losses=0.3606, top1=92.2000, 0=92.2000, 1=96.8000, 2=89.8000, 3=82.0000, 4=94.4000, 5=85.4000, 6=95.8000, 7=94.8000, 8=96.0000, 9=94.8000, test:, losses=0.3690, top1=92.3900, 0=93.1000, 1=97.4000, 2=88.3000, 3=83.5000, 4=94.4000, 5=87.7000, 6=95.0000, 7=94.6000, 8=95.6000, 9=94.3000, 28.6s 2.5h/2.7h
Epoch: [188]
epoch 188/200, train:, losses=0.0055, top1=99.8689, 0=99.8000, 1=99.8667, 2=99.8444, 3=99.8222, 4=99.9556, 5=99.7778, 6=99.8889, 7=99.8667, 8=99.9556, 9=99.9111, val:, losses=0.3618, top1=92.3400, 0=92.4000, 1=96.6000, 2=90.6000, 3=82.0000, 4=94.8000, 5=85.0000, 6=95.6000, 7=94.6000, 8=96.6000, 9=95.2000, test:, losses=0.3684, top1=92.3700, 0=92.5000, 1=97.6000, 2=88.3000, 3=83.2000, 4=95.3000, 5=87.3000, 6=94.6000, 7=94.6000, 8=95.8000, 9=94.5000, 28.1s 2.5h/2.7h
Epoch: [189]
epoch 189/200, train:, losses=0.0060, top1=99.8356, 0=99.8667, 1=99.9778, 2=99.7778, 3=99.6222, 4=99.8444, 5=99.7111, 6=99.9556, 7=99.9333, 8=99.9111, 9=99.7556, val:, losses=0.3582, top1=92.2600, 0=92.4000, 1=96.6000, 2=90.0000, 3=82.4000, 4=94.6000, 5=85.0000, 6=95.6000, 7=94.8000, 8=96.0000, 9=95.2000, test:, losses=0.3666, top1=92.4400, 0=93.0000, 1=97.3000, 2=88.6000, 3=83.1000, 4=95.1000, 5=87.5000, 6=94.7000, 7=94.7000, 8=95.7000, 9=94.7000, 27.6s 2.5h/2.7h
Epoch: [190]
epoch 190/200, train:, losses=0.0058, top1=99.8533, 0=99.9333, 1=99.8889, 2=99.8667, 3=99.7111, 4=99.8667, 5=99.6889, 6=99.9333, 7=99.9111, 8=99.8889, 9=99.8444, val:, losses=0.3628, top1=92.2200, 0=92.8000, 1=96.6000, 2=89.8000, 3=82.0000, 4=94.6000, 5=85.0000, 6=95.2000, 7=94.8000, 8=95.8000, 9=95.6000, test:, losses=0.3708, top1=92.2800, 0=93.5000, 1=97.1000, 2=88.5000, 3=82.7000, 4=95.0000, 5=87.8000, 6=93.8000, 7=94.6000, 8=95.1000, 9=94.7000, 27.8s 2.6h/2.7h
Epoch: [191]
epoch 191/200, train:, losses=0.0056, top1=99.8578, 0=99.9111, 1=99.9333, 2=99.8444, 3=99.7333, 4=99.8667, 5=99.7778, 6=99.8889, 7=99.8667, 8=99.8889, 9=99.8667, val:, losses=0.3641, top1=92.2400, 0=93.0000, 1=96.6000, 2=90.2000, 3=82.6000, 4=94.8000, 5=83.8000, 6=95.6000, 7=94.6000, 8=96.6000, 9=94.6000, test:, losses=0.3696, top1=92.4100, 0=92.9000, 1=97.3000, 2=88.8000, 3=84.4000, 4=95.2000, 5=86.6000, 6=94.6000, 7=94.5000, 8=95.9000, 9=93.9000, 28.2s 2.6h/2.7h
Epoch: [192]
epoch 192/200, train:, losses=0.0060, top1=99.8311, 0=99.8667, 1=99.9111, 2=99.7778, 3=99.6889, 4=99.8667, 5=99.7111, 6=99.9111, 7=99.8444, 8=99.9333, 9=99.8000, val:, losses=0.3633, top1=92.0800, 0=92.4000, 1=96.6000, 2=89.6000, 3=82.8000, 4=94.6000, 5=84.2000, 6=95.6000, 7=94.0000, 8=96.0000, 9=95.0000, test:, losses=0.3676, top1=92.3400, 0=93.4000, 1=97.2000, 2=87.9000, 3=84.8000, 4=94.8000, 5=87.0000, 6=94.4000, 7=94.3000, 8=95.2000, 9=94.4000, 27.5s 2.6h/2.7h
Epoch: [193]
epoch 193/200, train:, losses=0.0058, top1=99.8289, 0=99.8667, 1=99.8889, 2=99.8000, 3=99.6667, 4=99.8000, 5=99.7333, 6=99.9111, 7=99.9111, 8=99.8222, 9=99.8889, val:, losses=0.3627, top1=92.2400, 0=93.6000, 1=96.4000, 2=90.0000, 3=82.4000, 4=94.2000, 5=85.2000, 6=95.8000, 7=93.8000, 8=96.2000, 9=94.8000, test:, losses=0.3685, top1=92.3400, 0=93.6000, 1=97.0000, 2=88.4000, 3=84.0000, 4=94.4000, 5=87.9000, 6=94.3000, 7=94.2000, 8=95.5000, 9=94.1000, 28.2s 2.6h/2.7h
Epoch: [194]
epoch 194/200, train:, losses=0.0056, top1=99.8467, 0=99.8889, 1=99.8667, 2=99.7556, 3=99.7333, 4=99.8889, 5=99.8222, 6=99.8222, 7=99.8889, 8=99.9111, 9=99.8889, val:, losses=0.3639, top1=92.2000, 0=92.8000, 1=96.6000, 2=90.2000, 3=82.0000, 4=94.6000, 5=84.0000, 6=95.4000, 7=95.0000, 8=97.0000, 9=94.4000, test:, losses=0.3684, top1=92.3100, 0=93.3000, 1=97.4000, 2=88.8000, 3=83.3000, 4=94.7000, 5=86.7000, 6=94.0000, 7=94.8000, 8=96.0000, 9=94.1000, 27.7s 2.6h/2.7h
Epoch: [195]
epoch 195/200, train:, losses=0.0055, top1=99.8644, 0=99.9333, 1=99.8889, 2=99.8000, 3=99.7111, 4=99.8444, 5=99.7556, 6=99.9111, 7=99.9333, 8=99.9111, 9=99.9556, val:, losses=0.3636, top1=92.2200, 0=92.2000, 1=96.6000, 2=90.4000, 3=81.2000, 4=95.0000, 5=85.6000, 6=95.6000, 7=94.4000, 8=96.0000, 9=95.2000, test:, losses=0.3707, top1=92.4200, 0=92.7000, 1=97.3000, 2=88.6000, 3=83.1000, 4=94.9000, 5=88.3000, 6=94.4000, 7=94.5000, 8=95.4000, 9=95.0000, 27.6s 2.6h/2.7h
Epoch: [196]
epoch 196/200, train:, losses=0.0057, top1=99.8600, 0=99.9556, 1=99.8889, 2=99.8889, 3=99.6889, 4=99.9111, 5=99.7778, 6=99.8889, 7=99.8444, 8=99.9333, 9=99.8222, val:, losses=0.3650, top1=92.2600, 0=92.2000, 1=96.6000, 2=90.4000, 3=81.8000, 4=95.2000, 5=84.8000, 6=95.6000, 7=94.8000, 8=96.6000, 9=94.6000, test:, losses=0.3689, top1=92.3600, 0=92.5000, 1=97.4000, 2=89.0000, 3=83.2000, 4=95.1000, 5=87.3000, 6=94.5000, 7=94.6000, 8=95.9000, 9=94.1000, 27.2s 2.6h/2.7h
Epoch: [197]
epoch 197/200, train:, losses=0.0056, top1=99.8578, 0=99.8889, 1=99.9556, 2=99.7556, 3=99.7556, 4=99.8444, 5=99.7111, 6=99.9111, 7=99.9556, 8=99.9333, 9=99.8667, val:, losses=0.3628, top1=92.1600, 0=92.0000, 1=96.8000, 2=90.0000, 3=81.0000, 4=95.0000, 5=85.2000, 6=95.6000, 7=94.4000, 8=96.4000, 9=95.2000, test:, losses=0.3710, top1=92.4100, 0=93.1000, 1=97.4000, 2=88.3000, 3=82.8000, 4=95.1000, 5=88.1000, 6=94.7000, 7=94.3000, 8=95.6000, 9=94.7000, 27.2s 2.6h/2.6h
Epoch: [198]
epoch 198/200, train:, losses=0.0057, top1=99.8444, 0=99.8444, 1=99.9556, 2=99.9111, 3=99.6889, 4=99.9556, 5=99.6667, 6=99.9333, 7=99.7778, 8=99.8667, 9=99.8444, val:, losses=0.3659, top1=92.1200, 0=92.4000, 1=96.0000, 2=89.6000, 3=82.0000, 4=94.2000, 5=85.2000, 6=95.0000, 7=95.0000, 8=96.6000, 9=95.2000, test:, losses=0.3707, top1=92.4100, 0=93.4000, 1=96.9000, 2=88.2000, 3=84.0000, 4=95.1000, 5=88.0000, 6=93.9000, 7=94.6000, 8=95.7000, 9=94.3000, 26.8s 2.6h/2.6h
Epoch: [199]
epoch 199/200, train:, losses=0.0055, top1=99.8867, 0=99.8667, 1=99.8222, 2=99.8444, 3=99.8000, 4=99.8889, 5=99.8000, 6=99.9556, 7=99.9333, 8=99.9778, 9=99.9778, val:, losses=0.3633, top1=92.2200, 0=92.4000, 1=96.6000, 2=90.6000, 3=82.2000, 4=94.8000, 5=84.4000, 6=96.0000, 7=94.4000, 8=96.0000, 9=94.8000, test:, losses=0.3686, top1=92.3900, 0=92.9000, 1=97.3000, 2=89.3000, 3=84.2000, 4=94.9000, 5=86.9000, 6=94.2000, 7=94.4000, 8=95.5000, 9=94.3000, 28.0s 2.6h/2.6h
Epoch: [200]
epoch 200/200, train:, losses=0.0053, top1=99.8667, 0=99.9111, 1=99.9333, 2=99.8222, 3=99.8222, 4=99.7556, 5=99.8000, 6=99.9111, 7=99.8444, 8=99.9111, 9=99.9556, val:, losses=0.3626, top1=92.3600, 0=93.0000, 1=96.6000, 2=90.4000, 3=81.8000, 4=94.8000, 5=85.6000, 6=95.6000, 7=95.0000, 8=96.4000, 9=94.4000, test:, losses=0.3708, top1=92.3700, 0=92.8000, 1=97.5000, 2=89.1000, 3=82.5000, 4=94.9000, 5=88.0000, 6=94.6000, 7=94.7000, 8=95.6000, 9=94.0000, 26.1s 2.6h/2.6h
